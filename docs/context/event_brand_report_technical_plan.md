# üìã Plano T√©cnico Completo - Event Brand Report MVP
## Midiaz B2B - Intelig√™ncia Visual para Marketing Esportivo

**Vers√£o:** 1.0  
**Data:** 2025  
**Status:** MVP - Fase de Produ√ß√£o  
**Equipe:** Matheus Augusto (L√≠der T√©cnico), Lu√≠s Felipe Pascoal (Cientista de Dados), Rafaela Le√£o (Designer de Produto)

---

## 1. Resumo Executivo do MVP

### 1.1. Vis√£o Geral do Produto

O **Event Brand Report** √© o **MVP e primeiro produto** do Midiaz B2B, transformando fotos esportivas j√° processadas e armazenadas no S3 (pelo sistema B2C - marketplace) em insights estruturados sobre presen√ßa de marca em eventos esportivos. O MVP foca em processar um evento completo (ex.: Maratona do Recife) e entregar um relat√≥rio executivo que responde a tr√™s perguntas fundamentais:

1. **Quais marcas aparecem mais no evento?**
2. **Quais produtos s√£o mais usados pelos atletas?**
3. **Qual √© o share de mercado visual de cada marca?**

**Fonte de Dados:** O sistema consome fotos que j√° foram processadas e est√£o armazenadas no S3 pelo sistema Midiaz B2C (marketplace). Quando uma pessoa est√° cadastrada na Midiaz, temos acesso a dados cadastrais como CPF, idade, g√™nero, entre outros, que podem ser utilizados para enriquecimento dos dados.

### 1.2. Principais Entreg√°veis

| Entreg√°vel | Descri√ß√£o | Formato |
|------------|-----------|---------|
| **Pipeline de Processamento** | Sistema end-to-end que processa fotos e extrai dados | C√≥digo Python + Infraestrutura |
| **Dataset Anal√≠tico** | Tabelas estruturadas com m√©tricas de presen√ßa de marca | PostgreSQL + CSV/Parquet |
| **Relat√≥rio Executivo** | Documento PDF com insights em linguagem natural | PDF gerado via LLM |
| **Dashboard Interativo** | Visualiza√ß√µes explorat√≥rias dos dados | Metabase (recomendado) |
| **API de Consulta** | Endpoints REST para acessar dados agregados | FastAPI |

### 1.3. Motiva√ß√£o de Neg√≥cio

**Problema:** Marcas esportivas investem milh√µes em patroc√≠nios sem ter dados confi√°veis sobre presen√ßa real de seus produtos em eventos. Pesquisas declarativas s√£o imprecisas e caras.

**Solu√ß√£o MVP:** Automatizar a extra√ß√£o de dados visuais de eventos esportivos, transformando fotos em m√©tricas objetivas de presen√ßa de marca, permitindo:
- Medi√ß√£o precisa de ROI de patroc√≠nios
- Identifica√ß√£o de oportunidades de ativa√ß√£o
- Benchmarking competitivo em tempo real
- Decis√µes baseadas em evid√™ncias visuais

**Valor Proposto:** Reduzir o tempo de an√°lise de semanas para horas, com precis√£o superior a pesquisas tradicionais.

### 1.4. Stakeholders

| Stakeholder | Interesse |
|-------------|-----------|
| **Organizadores de Eventos** | Validar atratividade para patrocinadores atrav√©s de dados de presen√ßa de marca |
| **Marcas Patrocinadoras** | Medir ROI e efic√°cia de ativa√ß√µes com m√©tricas objetivas |
| **Midiaz (Interno)** | Validar proposta de valor B2B e criar case de sucesso |

**Nota:** Os entreg√°veis variam caso a caso, podendo incluir relat√≥rios PDF, dashboards interativos, APIs de dados ou datasets export√°veis, dependendo das necessidades espec√≠ficas de cada stakeholder.

### 1.5. Escopo do MVP - Dentro e Fora

#### ‚úÖ **DENTRO DO MVP**

1. **Processamento de 1 evento completo**
   - Ingest√£o de fotos j√° processadas e armazenadas no S3 (sistema B2C)
   - Processamento batch (n√£o real-time)
   - Suporte a 5-10 marcas principais (Nike, Adidas, Mizuno, Track&Field, etc.)
   - Enriquecimento com dados cadastrais quando pessoa est√° cadastrada na Midiaz (CPF, idade, g√™nero, etc.)

2. **Extra√ß√£o de dados b√°sicos**
   - Detec√ß√£o de marca (logotipo)
   - Categoria de produto (t√™nis, camiseta, bon√©, √≥culos)
   - Confian√ßa do modelo (score)
   - Metadados do evento (nome, local, data)

3. **M√©tricas calculadas**
   - Share de marca (%)
   - Volume absoluto de apari√ß√µes
   - Ranking de produtos
   - Total de atletas √∫nicos identificados

4. **Entrega anal√≠tica**
   - Relat√≥rio PDF automatizado (100-200 palavras)
   - Dashboard com 4-6 visualiza√ß√µes principais
   - Dataset tabular export√°vel (CSV)

5. **Infraestrutura m√≠nima**
   - Backend FastAPI
   - PostgreSQL para dados estruturados
   - S3 para armazenamento de imagens
   - Processamento via Lambda ou EC2

#### ‚ùå **FORA DO MVP (v2+)**

1. **Multi-evento e hist√≥rico**
   - Compara√ß√£o entre eventos
   - Tend√™ncias temporais
   - An√°lise de recorr√™ncia de atletas

2. **Detec√ß√µes avan√ßadas**
   - Bounding boxes precisos
   - Detec√ß√£o de idade/g√™nero
   - Classifica√ß√£o de n√≠vel de competi√ß√£o
   - Detec√ß√£o de contexto (in√≠cio/fim de prova)

3. **Produtos customizados**
   - API p√∫blica de dados
   - Integra√ß√£o com sistemas de CRM
   - Alertas e notifica√ß√µes autom√°ticas

4. **An√°lise preditiva**
   - Previs√£o de presen√ßa de marca
   - Recomenda√ß√µes de ativa√ß√£o
   - ROI forecasting

5. **Escala enterprise**
   - Processamento real-time
   - Multi-tenant
   - SLA garantido

---

## 2. Arquitetura Completa da Solu√ß√£o

### 2.1. Vis√£o Geral da Arquitetura

```mermaid
graph TB
    subgraph "Ingest√£o"
        A[Sistema B2C<br/>Marketplace] -->|Fotos Processadas| B[S3 Bucket<br/>Midiaz B2C]
        C[Metadados Evento] -->|JSON| D[API FastAPI]
    end
    
    subgraph "Processamento"
        B -->|Consome Fotos| E[Lambda/EC2 Processor]
        D -->|Event Metadata| E
        E -->|Vision API| F[AWS Rekognition/OpenAI Vision]
        F -->|Detections| G[PostgreSQL]
    end
    
    subgraph "Enriquecimento"
        G -->|CPF| I[Dados Cadastrais<br/>Midiaz B2C]
        I -->|Idade, G√™nero, etc| G
        G -->|Raw Detections| J[Data Enrichment Service]
        J -->|Normalized Data| G
    end
    
    subgraph "Agrega√ß√£o"
        G -->|Structured Data| K[Aggregation Engine]
        K -->|Metrics| L[Analytical Tables]
    end
    
    subgraph "Entrega"
        L -->|Data| M[Metabase Dashboard]
        L -->|Data| N[Report Generator LLM]
        N -->|PDF| O[S3 Reports]
        L -->|API| P[FastAPI REST]
    end
    
    style B fill:#e1f5ff
    style G fill:#fff4e1
    style L fill:#e8f5e9
    style M fill:#f3e5f5
    style O fill:#f3e5f5
```

**Decis√£o Arquitetural:** Optamos por uma arquitetura **h√≠brida serverless + containerizada**:
- **Serverless (Lambda)** para processamento batch de imagens (custo-efetivo)
- **Containerizado (EC2/Fargate)** para servi√ßos de longa dura√ß√£o (agrega√ß√£o, enriquecimento)
- **PostgreSQL** como fonte √∫nica de verdade (relacional para queries complexas)
- **S3** como data lake para imagens brutas e relat√≥rios gerados

### 2.2. Arquitetura de Dados

#### 2.2.1. Fluxo de Dados End-to-End

```mermaid
flowchart LR
    A[Fotos Processadas<br/>S3 B2C] -->|Consome| B[Person Detection<br/>+ Item Detection]
    B -->|Pessoas + Itens| C[Association Service<br/>Associa Itens a Pessoas]
    C -->|Pessoa + Itens| D[PostgreSQL<br/>Person Items]
    D -->|CPF| E[Enrichment<br/>Dados Cadastrais B2C]
    E -->|Idade, G√™nero| D
    D -->|ETL| F[Normalize Brands<br/>+ Products]
    F -->|Enriched| G[PostgreSQL<br/>Normalized Data]
    G -->|Aggregation| H[Analytical Tables<br/>Brand Metrics]
    H -->|Query| I[Dashboard/Report]
    
    style A fill:#ffebee
    style C fill:#fff3e0
    style D fill:#e8f5e9
    style H fill:#e3f2fd
```

#### 2.2.2. Camadas de Armazenamento

| Camada | Tecnologia | Prop√≥sito | Reten√ß√£o |
|--------|------------|-----------|----------|
| **Raw Images** | S3 (Standard) | Fotos originais do evento | 90 dias |
| **Processed Images** | S3 (Standard-IA) | Imagens pr√©-processadas | 30 dias |
| **Raw Detections** | PostgreSQL | Resultados brutos da API de vis√£o | Permanente |
| **Normalized Data** | PostgreSQL | Dados enriquecidos e validados | Permanente |
| **Analytical Tables** | PostgreSQL | M√©tricas agregadas por evento | Permanente |
| **Reports** | S3 (Standard) | PDFs gerados | 1 ano |

**Decis√£o:** Usar **PostgreSQL** em vez de DynamoDB porque:
- Queries anal√≠ticas complexas (JOINs, GROUP BY, window functions)
- Relacionamentos entre eventos, marcas, produtos
- Facilita cria√ß√£o de views materializadas
- Custo previs√≠vel (RDS t3.medium ~$70/m√™s)

#### 2.2.3. Cat√°logo de Dados

**Metadados do Evento (Event Metadata)**
```json
{
  "event_id": "uuid",
  "event_name": "Maratona do Recife 2025",
  "event_type": "corrida",
  "event_date": "2025-05-12",
  "event_location": "Recife, PE",
  "total_photos": 14532,
  "total_athletes_estimated": 8920,
  "photographer_ids": ["photographer_001", "photographer_002"],
  "status": "processing|completed|failed",
  "created_at": "2025-05-12T06:00:00Z",
  "processed_at": "2025-05-12T14:30:00Z"
}
```

**Metadados de Processamento**
- Vers√£o do modelo de vis√£o usado
- Timestamp de cada etapa
- Erros e retries
- Custo estimado de processamento

### 2.3. Arquitetura de Backend

#### 2.3.1. Servi√ßos Principais

```mermaid
graph TB
    subgraph "API Layer"
        A[FastAPI Gateway] -->|Routes| B[Event Controller]
        A -->|Routes| C[Report Controller]
        A -->|Routes| D[Data Controller]
    end
    
    subgraph "Business Logic"
        B -->|Orchestrates| E[Event Service]
        C -->|Orchestrates| F[Report Service]
        D -->|Orchestrates| G[Data Service]
        
        E -->|Uses| H[Ingestion Service]
        E -->|Uses| I[Processing Service]
        F -->|Uses| J[LLM Service]
        G -->|Uses| K[Aggregation Service]
    end
    
    subgraph "Data Layer"
        H -->|Writes| L[PostgreSQL]
        I -->|Writes| L
        K -->|Reads| L
        J -->|Reads| L
    end
    
    subgraph "External Services"
        I -->|Calls| M[AWS Rekognition]
        J -->|Calls| N[OpenAI API]
        H -->|Reads| O[S3 Bucket]
    end
    
    style A fill:#4fc3f7
    style E fill:#81c784
    style L fill:#ffb74d
    style M fill:#ba68c8
    style N fill:#ba68c8
```

#### 2.3.2. Fila/Event-Driven (Opcional no MVP)

**Recomenda√ß√£o:** **N√ÉO usar fila no MVP**. Processamento s√≠ncrono via Lambda com timeout de 15 minutos √© suficiente.

**Justificativa:**
- MVP processa 1 evento por vez
- Volume baixo (< 20k imagens/evento)
- Complexidade desnecess√°ria para MVP
- Custo adicional (SQS, EventBridge)

**Para v2:** Implementar SQS + Step Functions quando houver multi-evento e processamento paralelo.

#### 2.3.3. Orquestra√ß√£o

**MVP:** Processamento sequencial simples
```
1. Ingest√£o ‚Üí 2. Preprocessing ‚Üí 3. Vision API ‚Üí 4. Enrichment ‚Üí 5. Aggregation ‚Üí 6. Report Generation
```

**v2:** Step Functions para orquestra√ß√£o complexa com retry e error handling.

#### 2.3.4. API para Consulta (MVP)

**Endpoints Essenciais:**

```python
# Eventos
GET    /api/v1/events                    # Lista eventos
GET    /api/v1/events/{event_id}          # Detalhes do evento
POST   /api/v1/events                    # Cria novo evento
GET    /api/v1/events/{event_id}/status   # Status do processamento

# Relat√≥rios
GET    /api/v1/events/{event_id}/report   # Gera/retorna relat√≥rio PDF
GET    /api/v1/events/{event_id}/summary  # Resumo JSON

# Dados Anal√≠ticos
GET    /api/v1/events/{event_id}/brands   # Lista marcas detectadas
GET    /api/v1/events/{event_id}/products # Lista produtos detectados
GET    /api/v1/events/{event_id}/metrics # M√©tricas agregadas
```

**Decis√£o:** FastAPI porque:
- Async nativo (melhor para I/O com APIs externas)
- Valida√ß√£o autom√°tica com Pydantic
- Documenta√ß√£o autom√°tica (Swagger)
- F√°cil integra√ß√£o com servi√ßos Python (pandas, SQLAlchemy)

### 2.4. Arquitetura de IA e Vis√£o Computacional

#### 2.4.1. Modelo de Detec√ß√£o de Marca

**Recomenda√ß√£o MVP: AWS Rekognition Custom Labels**

**Por qu√™?**
- ‚úÖ Treinamento customizado com dataset de marcas esportivas
- ‚úÖ Alta precis√£o para logotipos conhecidos (Nike, Adidas, etc.)
- ‚úÖ Gerenciado pela AWS (sem infraestrutura pr√≥pria)
- ‚úÖ Custo: $1.00 por hora de treinamento + $4.00 por 1.000 imagens infer√™ncia

**Alternativa (se custo for limitante):** OpenAI Vision API
- ‚úÖ Boa detec√ß√£o zero-shot de marcas conhecidas
- ‚úÖ Custo: $0.01-0.03 por imagem
- ‚ùå Menos preciso que modelo customizado
- ‚ùå Pode ter alucina√ß√µes

**Estrat√©gia H√≠brida (Recomendada):**
1. **Fase 1 (MVP):** OpenAI Vision API para valida√ß√£o r√°pida
2. **Fase 2 (v1):** Treinar modelo customizado Rekognition com 500-1000 imagens anotadas
3. **Fase 3 (v2):** Fine-tuning cont√≠nuo com feedback loop

#### 2.4.2. Modelo de Detec√ß√£o de Categoria de Produto

**Recomenda√ß√£o: OpenAI Vision API com Prompt Engineering**

**Prompt Estruturado:**
```
Analise esta imagem de evento esportivo e identifique:
1. Tipo de produto esportivo vis√≠vel (t√™nis, camiseta, bon√©, √≥culos, short, meia)
2. Marca do produto (se identific√°vel)
3. Confian√ßa da detec√ß√£o (alto/m√©dio/baixo)

Retorne JSON:
{
  "products": [
    {
      "type": "t√™nis",
      "brand": "Nike",
      "confidence": "alto"
    }
  ]
}
```

**Por qu√™ n√£o modelo customizado?**
- Categorias s√£o gen√©ricas (t√™nis, camiseta) - n√£o precisa de treinamento
- OpenAI Vision tem boa performance zero-shot
- Custo menor que treinar modelo pr√≥prio

#### 2.4.3. Modelo de Estimativa de Idade/G√™nero (Opcional MVP)

**Status:** ‚ùå **FORA DO MVP**

**Justificativa:**
- Complexidade adicional sem valor imediato
- Quest√µes √©ticas de privacidade
- Baixa precis√£o em imagens esportivas (dist√¢ncia, movimento)

**Para v2:** Implementar com AWS Rekognition Face Analysis (se necess√°rio para segmenta√ß√£o demogr√°fica).

#### 2.4.4. Estrat√©gia de Infer√™ncia

**MVP: Processamento Batch Ass√≠ncrono**

```mermaid
sequenceDiagram
    participant U as User/API
    participant L as Lambda Processor
    participant R as Rekognition/Vision API
    participant DB as PostgreSQL
    participant S3 as S3 Bucket
    
    U->>L: Trigger processamento evento
    L->>S3: Lista imagens do evento
    loop Para cada imagem
        L->>R: Detect brands & products
        R-->>L: JSON detections
        L->>DB: Salva raw detection
    end
    L->>DB: Agrega m√©tricas
    L->>U: Status: completed
```

**Configura√ß√£o Lambda:**
- **Timeout:** 15 minutos (m√°ximo AWS)
- **Memory:** 3GB (para processar m√∫ltiplas imagens em paralelo)
- **Concurrency:** 1 (evitar rate limits da API)
- **Retry:** 3 tentativas com backoff exponencial

**Otimiza√ß√£o de Custo:**
- Processar imagens em batches de 10
- Cache de resultados (evitar reprocessar mesma imagem)
- Compress√£o de imagens antes do envio (reduz custo de API)

#### 2.4.5. Pipeline de Pr√©-processamento

**Etapas:**

1. **Valida√ß√£o de Imagem**
   - Formato suportado (JPEG, PNG)
   - Tamanho m√≠nimo (100x100px)
   - Tamanho m√°ximo (10MB)

2. **Normaliza√ß√£o**
   - Redimensionar para 1024x1024px (mant√©m aspect ratio)
   - Compress√£o JPEG qualidade 85%
   - Convers√£o para RGB (remove alpha channel)

3. **Otimiza√ß√£o para API**
   - Base64 encoding (se necess√°rio)
   - Batch de 10 imagens por requisi√ß√£o

**C√≥digo Exemplo:**
```python
from PIL import Image
import io

def preprocess_image(image_bytes: bytes) -> bytes:
    img = Image.open(io.BytesIO(image_bytes))
    img = img.convert('RGB')
    img.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
    
    output = io.BytesIO()
    img.save(output, format='JPEG', quality=85, optimize=True)
    return output.getvalue()
```

#### 2.4.6. Associa√ß√£o de Itens a Pessoas

**Problema Cr√≠tico:** Uma foto pode conter m√∫ltiplas pessoas, cada uma usando diferentes itens (t√™nis, camiseta, etc.). √â fundamental garantir que os itens detectados sejam corretamente associados √† pessoa que os est√° usando, evitando misturar itens de pessoas diferentes.

**Solu√ß√£o: Detec√ß√£o de Pessoas + Associa√ß√£o por Proximidade Espacial**

**Processo:**
1. **Detectar Pessoas:** Usar API de vis√£o para detectar pessoas na foto (bounding boxes)
2. **Detectar Itens:** Detectar marcas e produtos com seus bounding boxes
3. **Associar por Proximidade:** Para cada item, encontrar a pessoa mais pr√≥xima usando c√°lculo de dist√¢ncia entre bounding boxes
4. **Validar Associa√ß√£o:** Item deve estar dentro ou pr√≥ximo do bounding box da pessoa (threshold configur√°vel)
5. **Calcular Confian√ßa:** `association_confidence` baseado na proximidade e sobreposi√ß√£o

**Algoritmo de Associa√ß√£o:**

```python
def associate_items_to_persons(photo_id, persons_detections, items_detections):
    """
    Associa itens detectados √†s pessoas corretas na foto.
    
    Args:
        persons_detections: Lista de detec√ß√µes de pessoas com bounding boxes
        items_detections: Lista de detec√ß√µes de itens (marcas/produtos) com bounding boxes
    
    Returns:
        Lista de associa√ß√µes pessoa-item com confian√ßa
    """
    associations = []
    
    for item in items_detections:
        best_person = None
        best_distance = float('inf')
        best_overlap = 0
        
        for person in persons_detections:
            # Calcular dist√¢ncia entre centros dos bounding boxes
            distance = euclidean_distance(
                get_center(item.bbox),
                get_center(person.bbox)
            )
            
            # Calcular sobreposi√ß√£o (IoU - Intersection over Union)
            overlap = calculate_iou(item.bbox, person.bbox)
            
            # Verificar se item est√° dentro ou pr√≥ximo da pessoa
            if is_item_near_person(item.bbox, person.bbox, threshold=50):
                # Priorizar sobreposi√ß√£o, depois dist√¢ncia
                if overlap > best_overlap or (overlap == best_overlap and distance < best_distance):
                    best_distance = distance
                    best_overlap = overlap
                    best_person = person
        
        if best_person:
            # Calcular confian√ßa da associa√ß√£o
            association_confidence = calculate_association_confidence(
                item.bbox,
                best_person.bbox,
                best_distance,
                best_overlap
            )
            
            associations.append({
                'person_id': best_person.id,
                'item': item,
                'association_confidence': association_confidence,
                'distance': best_distance,
                'overlap': best_overlap
            })
        else:
            # Item n√£o associado a nenhuma pessoa (pode ser item solto na foto)
            associations.append({
                'person_id': None,
                'item': item,
                'association_confidence': 0.0,
                'note': 'item_not_associated'
            })
    
    return associations

def calculate_association_confidence(item_bbox, person_bbox, distance, overlap):
    """
    Calcula confian√ßa da associa√ß√£o baseado em:
    - Sobreposi√ß√£o (IoU): quanto maior, melhor
    - Dist√¢ncia: quanto menor, melhor
    """
    # Normalizar dist√¢ncia (assumindo imagem 1024x1024)
    normalized_distance = distance / 1448.0  # diagonal m√°xima
    
    # F√≥rmula: overlap tem peso 0.7, dist√¢ncia tem peso 0.3
    confidence = (overlap * 0.7) + ((1 - normalized_distance) * 0.3)
    
    return min(1.0, max(0.0, confidence))
```

**Requisitos T√©cnicos:**
- **Bounding boxes obrigat√≥rios:** Tanto para pessoas quanto para itens
- **API de detec√ß√£o de pessoas:** AWS Rekognition DetectFaces ou similar
- **Threshold de proximidade:** Configur√°vel (padr√£o: 50 pixels)
- **Filtro de confian√ßa:** Associa√ß√µes com `association_confidence < 0.5` podem ser descartadas

**Casos Especiais:**
- **Item n√£o associado:** Se item n√£o est√° pr√≥ximo de nenhuma pessoa, pode ser descartado ou marcado como "n√£o associado"
- **M√∫ltiplos itens da mesma pessoa:** Uma pessoa pode ter m√∫ltiplos itens (t√™nis + camiseta + bon√©)
- **Item parcialmente vis√≠vel:** Se apenas parte do item est√° vis√≠vel, usar bounding box parcial

#### 2.4.7. Armazenamento de Resultados

**Estrutura no PostgreSQL:**

```sql
-- Tabela de detec√ß√µes brutas
CREATE TABLE raw_detections (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_id UUID NOT NULL REFERENCES events(id),
    photo_s3_key VARCHAR(500) NOT NULL,
    detection_type VARCHAR(50) NOT NULL, -- 'brand' ou 'product'
    detected_label VARCHAR(200),
    confidence_score DECIMAL(5,4),
    bounding_box JSONB, -- {x, y, width, height} - NULL no MVP
    raw_response JSONB, -- Resposta completa da API
    created_at TIMESTAMP DEFAULT NOW()
);

-- √çndices para performance
CREATE INDEX idx_raw_detections_event ON raw_detections(event_id);
CREATE INDEX idx_raw_detections_type ON raw_detections(detection_type);
CREATE INDEX idx_raw_detections_label ON raw_detections(detected_label);
```

### 2.5. Arquitetura do Produto Anal√≠tico

#### 2.5.1. Decis√£o: Dashboard + Relat√≥rio PDF

**Recomenda√ß√£o:** **Ambos no MVP**

**Justificativa:**
- **Dashboard (Metabase):** Explora√ß√£o interativa, drill-down, filtros
- **Relat√≥rio PDF:** Documento executivo para apresenta√ß√µes, email, impress√£o

**Custo:** Metabase Open Source (self-hosted) = $0 | Metabase Cloud = $85/m√™s

#### 2.5.2. Dashboard - Metabase (Recomendado)

**Por qu√™ Metabase?**
- ‚úÖ Open source (sem custo no MVP)
- ‚úÖ F√°cil conex√£o com PostgreSQL
- ‚úÖ Interface intuitiva (n√£o precisa de SQL avan√ßado)
- ‚úÖ Embedding poss√≠vel (para v2)
- ‚úÖ Suporte a exporta√ß√£o (CSV, PDF, XLSX)

**Alternativas Consideradas:**
- **Superset:** Mais complexo, curva de aprendizado maior
- **Power BI Embedded:** Custo alto ($10/usu√°rio/m√™s)
- **Looker Studio:** Gratuito mas limitado, depend√™ncia Google

**Visualiza√ß√µes Principais (MVP):**

1. **Share de Marca (Pizza Chart)**
   - % de cada marca no evento
   - Filtro por categoria de produto

2. **Ranking de Marcas (Bar Chart)**
   - Volume absoluto de apari√ß√µes
   - Ordenado por share

3. **Distribui√ß√£o de Produtos (Treemap)**
   - T√™nis vs Camiseta vs Acess√≥rios
   - Cores por marca

4. **Timeline de Detec√ß√µes (Line Chart)**
   - Apari√ß√µes ao longo do evento (se timestamp dispon√≠vel)

5. **Tabela Detalhada (Data Table)**
   - Marca | Produto | Apari√ß√µes | Share | Confian√ßa M√©dia

**Fonte de Dados:** Views materializadas no PostgreSQL

```sql
CREATE MATERIALIZED VIEW brand_event_summary AS
SELECT 
    e.id as event_id,
    e.event_name,
    b.normalized_brand,
    COUNT(DISTINCT rd.id) as total_detections,
    COUNT(DISTINCT rd.photo_s3_key) as photos_with_brand,
    AVG(rd.confidence_score) as avg_confidence,
    ROUND(
        100.0 * COUNT(DISTINCT rd.id) / 
        (SELECT COUNT(*) FROM raw_detections WHERE event_id = e.id),
        2
    ) as brand_share_percent
FROM events e
JOIN raw_detections rd ON rd.event_id = e.id
JOIN brand_normalization b ON b.detected_label = rd.detected_label
WHERE rd.detection_type = 'brand'
GROUP BY e.id, e.event_name, b.normalized_brand;
```

#### 2.5.3. Relat√≥rio PDF Automatizado

**Stack:**
- **LLM:** OpenAI GPT-4 (ou GPT-3.5-turbo para custo)
- **Template Engine:** Jinja2
- **PDF Generator:** ReportLab ou WeasyPrint
- **Storage:** S3 (acesso via URL assinada)

**Fluxo:**

```mermaid
graph LR
    A[Agrega√ß√£o Completa] -->|Dados JSON| B[LLM Service]
    B -->|Prompt + Context| C[OpenAI API]
    C -->|Texto Narrativo| D[Template Engine]
    D -->|HTML/Markdown| E[PDF Generator]
    E -->|PDF| F[S3 Bucket]
    F -->|URL| G[API Response]
```

**Template do Prompt (do documento de Idea√ß√£o):**

```python
PROMPT_TEMPLATE = """
Voc√™ √© um analista de marketing esportivo da plataforma Midiaz.

Com base nas seguintes informa√ß√µes visuais, gere um relat√≥rio executivo sobre a presen√ßa de marca.

Dados:
- Evento: {event_name}
- Local: {event_location}
- Data: {event_date}
- Total de atletas identificados: {total_athletes}
- Total de imagens analisadas: {total_images}
- Marcas detectadas e frequ√™ncia:
{brands_list}

Instru√ß√µes:
1. Resuma os principais destaques sobre a presen√ßa de marca.
2. Destaque a marca mais recorrente e o tipo de produto mais identificado.
3. Contextualize brevemente o tipo de evento esportivo.
4. A sa√≠da deve estar em linguagem natural, formal e voltada para gestores de marketing esportivo.
5. Finalize o relat√≥rio com um insight estrat√©gico curto (1 frase) sobre como a marca pode otimizar seu desempenho futuro.
"""
```

**Estrutura do PDF:**
1. Capa (logo Midiaz, nome do evento, data)
2. Resumo Executivo (2-3 par√°grafos do LLM)
3. M√©tricas Principais (tabela com top 5 marcas)
4. Visualiza√ß√µes (gr√°ficos exportados do Metabase)
5. Detalhamento por Categoria (t√™nis, camiseta, etc.)
6. Insight Estrat√©gico (destaque do LLM)

**Custo Estimado:** $0.03-0.06 por relat√≥rio (GPT-3.5-turbo)

---

## 3. Design do Software

### 3.1. M√≥dulos do Sistema

```
midiaz-b2b/
‚îú‚îÄ‚îÄ ingestion/              # M√≥dulo de ingest√£o
‚îÇ   ‚îú‚îÄ‚îÄ s3_loader.py        # Carrega imagens do S3
‚îÇ   ‚îú‚îÄ‚îÄ metadata_parser.py  # Parse metadados do evento
‚îÇ   ‚îî‚îÄ‚îÄ validator.py        # Valida√ß√£o de entrada
‚îÇ
‚îú‚îÄ‚îÄ preprocessing/          # Pr√©-processamento de imagens
‚îÇ   ‚îú‚îÄ‚îÄ image_normalizer.py # Redimensiona, comprime
‚îÇ   ‚îú‚îÄ‚îÄ batch_processor.py  # Agrupa imagens em batches
‚îÇ   ‚îî‚îÄ‚îÄ quality_checker.py  # Valida qualidade da imagem
‚îÇ
‚îú‚îÄ‚îÄ vision_extraction/      # Integra√ß√£o com APIs de vis√£o
‚îÇ   ‚îú‚îÄ‚îÄ rekognition_client.py  # Cliente AWS Rekognition
‚îÇ   ‚îú‚îÄ‚îÄ openai_vision_client.py # Cliente OpenAI Vision
‚îÇ   ‚îú‚îÄ‚îÄ detection_parser.py    # Parse respostas da API
‚îÇ   ‚îî‚îÄ‚îÄ confidence_filter.py   # Filtra por confian√ßa m√≠nima
‚îÇ
‚îú‚îÄ‚îÄ person_association/    # Associa√ß√£o de itens a pessoas
‚îÇ   ‚îú‚îÄ‚îÄ person_detector.py     # Detecta pessoas na foto
‚îÇ   ‚îú‚îÄ‚îÄ item_associator.py     # Associa itens a pessoas por proximidade
‚îÇ   ‚îú‚îÄ‚îÄ bbox_calculator.py     # C√°lculos de bounding boxes (IoU, dist√¢ncia)
‚îÇ   ‚îî‚îÄ‚îÄ association_validator.py # Valida associa√ß√µes
‚îÇ
‚îú‚îÄ‚îÄ data_enrichment/       # Enriquecimento de dados
‚îÇ   ‚îú‚îÄ‚îÄ brand_normalizer.py    # Normaliza nomes de marcas
‚îÇ   ‚îú‚îÄ‚îÄ product_classifier.py  # Classifica produtos
‚îÇ   ‚îî‚îÄ‚îÄ metadata_enricher.py   # Adiciona contexto
‚îÇ
‚îú‚îÄ‚îÄ dataset_writer/         # Escrita no banco
‚îÇ   ‚îú‚îÄ‚îÄ db_writer.py       # Insere no PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ schema_validator.py # Valida schemas
‚îÇ   ‚îî‚îÄ‚îÄ batch_inserter.py  # Inser√ß√£o em lote otimizada
‚îÇ
‚îú‚îÄ‚îÄ aggregation/           # Agrega√ß√£o de m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ brand_aggregator.py   # Agrega por marca
‚îÇ   ‚îú‚îÄ‚îÄ product_aggregator.py # Agrega por produto
‚îÇ   ‚îî‚îÄ‚îÄ metrics_calculator.py # Calcula shares, rankings
‚îÇ
‚îú‚îÄ‚îÄ report_generator/      # Gera√ß√£o de relat√≥rios
‚îÇ   ‚îú‚îÄ‚îÄ llm_service.py     # Integra√ß√£o com OpenAI
‚îÇ   ‚îú‚îÄ‚îÄ prompt_builder.py  # Constr√≥i prompts
‚îÇ   ‚îú‚îÄ‚îÄ pdf_generator.py   # Gera PDF
‚îÇ   ‚îî‚îÄ‚îÄ template_engine.py # Template Jinja2
‚îÇ
‚îú‚îÄ‚îÄ api/                   # API FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ events.py      # Rotas de eventos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reports.py     # Rotas de relat√≥rios
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data.py        # Rotas de dados
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Pydantic models
‚îÇ   ‚îî‚îÄ‚îÄ dependencies.py    # Inje√ß√£o de depend√™ncias
‚îÇ
‚îî‚îÄ‚îÄ infrastructure/        # Infraestrutura
    ‚îú‚îÄ‚îÄ database.py        # Conex√£o PostgreSQL
    ‚îú‚îÄ‚îÄ s3_client.py       # Cliente S3
    ‚îî‚îÄ‚îÄ config.py          # Configura√ß√µes
```

### 3.2. Estrutura de Pastas do Projeto

```
midiaz-top4/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ BUILD.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ CONTEXT.md
‚îÇ   ‚îú‚îÄ‚îÄ event_brand_report_technical_plan.md
‚îÇ   ‚îú‚îÄ‚îÄ etapas/
‚îÇ   ‚îî‚îÄ‚îÄ arquitetura/
‚îÇ       ‚îú‚îÄ‚îÄ c4_context.md
‚îÇ       ‚îú‚îÄ‚îÄ c4_container.md
‚îÇ       ‚îî‚îÄ‚îÄ c4_component.md
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/
‚îÇ   ‚îú‚îÄ‚îÄ vision_extraction/
‚îÇ   ‚îú‚îÄ‚îÄ data_enrichment/
‚îÇ   ‚îú‚îÄ‚îÄ dataset_writer/
‚îÇ   ‚îú‚îÄ‚îÄ aggregation/
‚îÇ   ‚îú‚îÄ‚îÄ report_generator/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ e2e/
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup_db.sql
‚îÇ   ‚îú‚îÄ‚îÄ seed_brands.py
‚îÇ   ‚îî‚îÄ‚îÄ process_event.py
‚îÇ
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ terraform/         # IaC (opcional no MVP)
‚îÇ   ‚îî‚îÄ‚îÄ cloudformation/    # CloudFormation templates
‚îÇ
‚îî‚îÄ‚îÄ .github/
    ‚îî‚îÄ‚îÄ workflows/
        ‚îî‚îÄ‚îÄ ci.yml
```

**Explica√ß√£o de Diret√≥rios:**

- **`docs/`**: Documenta√ß√£o t√©cnica e metodol√≥gica
- **`src/`**: C√≥digo-fonte organizado por m√≥dulos
- **`tests/`**: Testes unit√°rios, integra√ß√£o e end-to-end
- **`scripts/`**: Scripts utilit√°rios (setup, seed, processamento manual)
- **`infrastructure/`**: C√≥digo de infraestrutura como c√≥digo (IaC)

### 3.3. Padr√µes de Design Recomendados

#### 3.3.1. Arquitetura Hexagonal (Ports & Adapters)

**Aplica√ß√£o no MVP:**

```python
# Port (Interface)
class VisionServicePort(ABC):
    @abstractmethod
    def detect_brands(self, image_bytes: bytes) -> List[BrandDetection]:
        pass

# Adapter (Implementa√ß√£o)
class RekognitionAdapter(VisionServicePort):
    def detect_brands(self, image_bytes: bytes) -> List[BrandDetection]:
        # Implementa√ß√£o espec√≠fica AWS Rekognition
        pass

class OpenAIVisionAdapter(VisionServicePort):
    def detect_brands(self, image_bytes: bytes) -> List[BrandDetection]:
        # Implementa√ß√£o espec√≠fica OpenAI
        pass

# Use Case (Core Business Logic)
class ProcessImageUseCase:
    def __init__(self, vision_service: VisionServicePort):
        self.vision_service = vision_service
    
    def execute(self, image: Image) -> ProcessedImage:
        detections = self.vision_service.detect_brands(image.bytes)
        return ProcessedImage(image, detections)
```

**Benef√≠cios:**
- Troca de provedor de vis√£o sem alterar l√≥gica de neg√≥cio
- Testes unit√°rios com mocks f√°ceis
- Desacoplamento de depend√™ncias externas

#### 3.3.2. Princ√≠pios SOLID Aplicados

**S - Single Responsibility:**
- Cada m√≥dulo tem uma responsabilidade √∫nica
- Ex: `brand_normalizer.py` s√≥ normaliza marcas, n√£o faz queries no banco

**O - Open/Closed:**
- Extens√≠vel via interfaces (Ports)
- Ex: Adicionar novo provedor de vis√£o sem modificar c√≥digo existente

**L - Liskov Substitution:**
- Adapters s√£o substitu√≠veis
- Ex: `RekognitionAdapter` e `OpenAIVisionAdapter` s√£o intercambi√°veis

**I - Interface Segregation:**
- Interfaces espec√≠ficas (n√£o uma interface gigante)
- Ex: `VisionServicePort` separado de `ReportServicePort`

**D - Dependency Inversion:**
- Depender de abstra√ß√µes, n√£o implementa√ß√µes
- Ex: `ProcessImageUseCase` depende de `VisionServicePort`, n√£o de `RekognitionAdapter`

#### 3.3.3. DTOs, Schemas e Valida√ß√µes

**Pydantic Models (DTOs):**

```python
from pydantic import BaseModel, Field, validator
from typing import List, Optional
from decimal import Decimal

class BrandDetection(BaseModel):
    brand: str = Field(..., min_length=1, max_length=200)
    confidence: Decimal = Field(..., ge=0, le=1)
    bounding_box: Optional[dict] = None
    
    @validator('brand')
    def normalize_brand(cls, v):
        return v.strip().title()

class ProductDetection(BaseModel):
    product_type: str = Field(..., regex='^(t√™nis|camiseta|bon√©|√≥culos|short|meia)$')
    brand: Optional[str] = None
    confidence: Decimal = Field(..., ge=0, le=1)

class EventMetadata(BaseModel):
    event_name: str = Field(..., min_length=3, max_length=200)
    event_date: date
    event_location: str
    event_type: str = Field(..., regex='^(corrida|triatlo|beach tennis|ciclismo)$')
    
    class Config:
        json_schema_extra = {
            "example": {
                "event_name": "Maratona do Recife 2025",
                "event_date": "2025-05-12",
                "event_location": "Recife, PE",
                "event_type": "corrida"
            }
        }
```

**Valida√ß√£o de Schemas no Banco:**

```python
# Usar SQLAlchemy com valida√ß√£o
from sqlalchemy import Column, String, DECIMAL, JSON
from sqlalchemy.dialects.postgresql import UUID
import uuid

class RawDetection(Base):
    __tablename__ = 'raw_detections'
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    detected_label = Column(String(200), nullable=False)
    confidence_score = Column(DECIMAL(5, 4), nullable=False)
    
    @validates('confidence_score')
    def validate_confidence(self, key, value):
        if not (0 <= value <= 1):
            raise ValueError("Confidence must be between 0 and 1")
        return value
```

#### 3.3.4. Padr√µes para M√≥dulos de IA

**1. Strategy Pattern para M√∫ltiplos Modelos:**

```python
class VisionModelStrategy(ABC):
    @abstractmethod
    def detect(self, image: bytes) -> DetectionResult:
        pass

class RekognitionStrategy(VisionModelStrategy):
    def detect(self, image: bytes) -> DetectionResult:
        # L√≥gica espec√≠fica Rekognition
        pass

class VisionModelFactory:
    @staticmethod
    def create(model_type: str) -> VisionModelStrategy:
        if model_type == "rekognition":
            return RekognitionStrategy()
        elif model_type == "openai":
            return OpenAIVisionStrategy()
        else:
            raise ValueError(f"Unknown model: {model_type}")
```

**2. Retry Pattern para APIs Externas:**

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def call_vision_api(image: bytes) -> DetectionResult:
    # Chamada √† API com retry autom√°tico
    pass
```

**3. Circuit Breaker para Preven√ß√£o de Cascata:**

```python
from circuitbreaker import circuit

@circuit(failure_threshold=5, recovery_timeout=60)
def call_external_api(image: bytes):
    # Se 5 falhas consecutivas, para de tentar por 60s
    pass
```

### 3.4. Fluxos Ass√≠ncronos vs S√≠ncronos

#### 3.4.1. Processamento S√≠ncrono (MVP)

**Quando usar:**
- Upload de metadados do evento
- Consulta de relat√≥rio j√° gerado
- API de m√©tricas (dados j√° agregados)

**Exemplo:**
```python
@app.post("/api/v1/events")
async def create_event(event: EventMetadata):
    # Cria evento no banco (s√≠ncrono, r√°pido)
    event_id = event_service.create(event)
    return {"event_id": event_id, "status": "created"}
```

#### 3.4.2. Processamento Ass√≠ncrono (MVP)

**Quando usar:**
- Processamento de imagens (pode levar minutos/horas)
- Gera√ß√£o de relat√≥rio PDF (chamada LLM + gera√ß√£o PDF)

**Estrat√©gia MVP:**
```python
@app.post("/api/v1/events/{event_id}/process")
async def trigger_processing(event_id: str):
    # Dispara processamento ass√≠ncrono
    # Retorna imediatamente com status "processing"
    process_event_async.delay(event_id)  # Celery ou Lambda
    return {"status": "processing", "event_id": event_id}

@app.get("/api/v1/events/{event_id}/status")
async def get_processing_status(event_id: str):
    # Consulta status do processamento
    status = event_service.get_status(event_id)
    return {"status": status}  # "processing" | "completed" | "failed"
```

**Implementa√ß√£o com Lambda:**
- API recebe requisi√ß√£o
- Dispara Lambda ass√≠ncrona via EventBridge
- Lambda processa em background
- Status atualizado no banco
- Cliente consulta status via polling

#### 3.4.3. Processamento Batch

**Quando usar:**
- Processamento de m√∫ltiplas imagens
- Agrega√ß√£o de m√©tricas
- Gera√ß√£o de relat√≥rios em lote

**Exemplo:**
```python
def process_event_batch(event_id: str):
    images = s3_service.list_images(event_id)
    
    # Processa em batches de 10
    for batch in chunks(images, 10):
        detections = vision_service.detect_batch(batch)
        db_writer.save_batch(detections)
    
    # Ap√≥s todas as imagens processadas
    aggregation_service.aggregate(event_id)
    report_service.generate(event_id)
```

---

## 4. Especifica√ß√£o Detalhada dos Dados

### 4.1. Campos Extra√≠dos das Imagens

#### 4.1.1. Detec√ß√£o de Marca

| Campo | Tipo | Descri√ß√£o | Exemplo | Obrigat√≥rio MVP |
|-------|------|-----------|---------|-----------------|
| `brand` | String(200) | Nome da marca detectada | "Nike" | ‚úÖ |
| `confidence` | Decimal(5,4) | Confian√ßa do modelo (0-1) | 0.9234 | ‚úÖ |
| `bounding_box` | JSONB | Coordenadas {x, y, width, height} | `{"x": 100, "y": 200, "width": 50, "height": 30}` | ‚ùå (v2) |
| `detection_type` | String(50) | Tipo: "brand" ou "product" | "brand" | ‚úÖ |
| `photo_s3_key` | String(500) | Chave S3 da imagem | "events/recife-2025/photo_001.jpg" | ‚úÖ |
| `timestamp` | Timestamp | Quando a detec√ß√£o foi feita | 2025-05-12T14:30:00Z | ‚úÖ |

#### 4.1.2. Detec√ß√£o de Produto

| Campo | Tipo | Descri√ß√£o | Exemplo | Obrigat√≥rio MVP |
|-------|------|-----------|---------|-----------------|
| `product_type` | String(50) | Categoria do produto | "t√™nis" | ‚úÖ |
| `brand` | String(200) | Marca associada (se detectada) | "Adidas" | ‚ö†Ô∏è (opcional) |
| `confidence` | Decimal(5,4) | Confian√ßa do modelo | 0.8567 | ‚úÖ |
| `subcategory` | String(100) | Subcategoria (ex: "t√™nis corrida") | "t√™nis corrida" | ‚ùå (v2) |

#### 4.1.3. Metadados da Pessoa/Atleta

| Campo | Tipo | Descri√ß√£o | Exemplo | Obrigat√≥rio MVP |
|-------|------|-----------|---------|-----------------|
| `cpf` | String(11) | CPF da pessoa (chave para enriquecimento) | "12345678901" | ‚úÖ (se cadastrada) |
| `person_id` | UUID | ID √∫nico da pessoa no evento | uuid | ‚úÖ |
| `age` | Integer | Idade (se dispon√≠vel via dados cadastrais) | 35 | ‚ö†Ô∏è (se cadastrada) |
| `gender` | String(10) | G√™nero (se dispon√≠vel via dados cadastrais) | "M" ou "F" | ‚ö†Ô∏è (se cadastrada) |
| `photo_count` | Integer | Quantas fotos a pessoa aparece | 5 | ‚úÖ |
| `first_seen` | Timestamp | Primeira apari√ß√£o no evento | 2025-05-12T06:00:00Z | ‚úÖ |
| `last_seen` | Timestamp | √öltima apari√ß√£o | 2025-05-12T10:30:00Z | ‚úÖ |

**Nota:** Cada pessoa tem um registro √∫nico por evento. Se a pessoa est√° cadastrada na Midiaz, temos CPF e dados cadastrais (idade, g√™nero, etc.) para enriquecimento. Se n√£o estiver cadastrada, o registro ter√° apenas `person_id` gerado.

#### 4.1.4. Metadados do Fot√≥grafo

| Campo | Tipo | Descri√ß√£o | Exemplo | Obrigat√≥rio MVP |
|-------|------|-----------|---------|-----------------|
| `photographer_id` | String(100) | ID do fot√≥grafo | "photographer_001" | ‚úÖ |
| `photos_uploaded` | Integer | Total de fotos enviadas | 14532 | ‚úÖ |
| `upload_timestamp` | Timestamp | Quando as fotos foram enviadas | 2025-05-12T05:00:00Z | ‚úÖ |

#### 4.1.5. Posi√ß√£o no Evento (Opcional)

| Campo | Tipo | Descri√ß√£o | Exemplo | Obrigat√≥rio MVP |
|-------|------|-----------|---------|-----------------|
| `event_position` | String(50) | Localiza√ß√£o no evento | "in√≠cio" | ‚ùå (v2) |
| `kilometer_marker` | Integer | Marca de quil√¥metro (se corrida) | 5 | ‚ùå (v2) |
| `time_of_day` | Time | Hor√°rio da foto | 06:30:00 | ‚ö†Ô∏è (se dispon√≠vel) |

### 4.2. Modelo Tabular Final

**Princ√≠pio Fundamental:** Cada registro na tabela de dados extra√≠dos representa **UMA PESSOA** em um evento espec√≠fico. Mesmo que a mesma pessoa apare√ßa em m√∫ltiplas fotos, h√° apenas um registro por pessoa por evento. Os itens detectados (marcas, produtos) s√£o associados √† pessoa atrav√©s de bounding boxes e detec√ß√£o de pessoas.

#### 4.2.1. Tabela: `events`

Armazena metadados dos eventos esportivos.

```sql
CREATE TABLE events (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_name VARCHAR(200) NOT NULL,
    event_type VARCHAR(50) NOT NULL CHECK (event_type IN ('corrida', 'triatlo', 'beach tennis', 'ciclismo')),
    event_date DATE NOT NULL,
    event_location VARCHAR(200) NOT NULL,
    total_photos INTEGER DEFAULT 0,
    total_athletes_estimated INTEGER,
    status VARCHAR(50) DEFAULT 'created' CHECK (status IN ('created', 'processing', 'completed', 'failed')),
    created_at TIMESTAMP DEFAULT NOW(),
    processed_at TIMESTAMP,
    metadata JSONB, -- Metadados adicionais flex√≠veis
    UNIQUE(event_name, event_date)
);

CREATE INDEX idx_events_date ON events(event_date);
CREATE INDEX idx_events_status ON events(status);
```

**Campos:**
- `id`: Identificador √∫nico do evento
- `event_name`: Nome do evento (ex: "Maratona do Recife 2025")
- `event_type`: Tipo de esporte
- `event_date`: Data do evento
- `event_location`: Localiza√ß√£o (cidade, estado)
- `total_photos`: Total de fotos processadas
- `total_athletes_estimated`: Estimativa de atletas √∫nicos
- `status`: Status do processamento
- `metadata`: JSON flex√≠vel para dados adicionais

#### 4.2.2. Tabela: `photos_raw`

Registro de todas as fotos processadas.

```sql
CREATE TABLE photos_raw (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_id UUID NOT NULL REFERENCES events(id) ON DELETE CASCADE,
    s3_key VARCHAR(500) NOT NULL,
    s3_bucket VARCHAR(200) NOT NULL,
    file_size_bytes BIGINT,
    image_width INTEGER,
    image_height INTEGER,
    photographer_id VARCHAR(100),
    uploaded_at TIMESTAMP,
    processed_at TIMESTAMP DEFAULT NOW(),
    processing_status VARCHAR(50) DEFAULT 'pending',
    UNIQUE(event_id, s3_key)
);

CREATE INDEX idx_photos_event ON photos_raw(event_id);
CREATE INDEX idx_photos_status ON photos_raw(processing_status);
```

#### 4.2.3. Tabela: `event_persons`

**Registro √∫nico de cada pessoa por evento.** Esta √© a tabela central que garante que cada pessoa tenha apenas um registro por evento, mesmo aparecendo em m√∫ltiplas fotos.

```sql
CREATE TABLE event_persons (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_id UUID NOT NULL REFERENCES events(id) ON DELETE CASCADE,
    cpf VARCHAR(11), -- CPF se pessoa est√° cadastrada na Midiaz (chave para enriquecimento)
    person_id UUID NOT NULL, -- ID √∫nico da pessoa (gerado ou do sistema B2C)
    age INTEGER, -- Idade (se dispon√≠vel via dados cadastrais)
    gender VARCHAR(10), -- G√™nero (se dispon√≠vel via dados cadastrais)
    photo_count INTEGER DEFAULT 0, -- Quantas fotos a pessoa aparece
    first_seen TIMESTAMP, -- Primeira apari√ß√£o no evento
    last_seen TIMESTAMP, -- √öltima apari√ß√£o no evento
    is_registered BOOLEAN DEFAULT FALSE, -- Se pessoa est√° cadastrada na Midiaz
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(event_id, person_id), -- Garante registro √∫nico por pessoa por evento
    UNIQUE(event_id, cpf) -- Se CPF dispon√≠vel, tamb√©m garante unicidade
);

CREATE INDEX idx_persons_event ON event_persons(event_id);
CREATE INDEX idx_persons_cpf ON event_persons(cpf) WHERE cpf IS NOT NULL;
CREATE INDEX idx_persons_person_id ON event_persons(person_id);
```

**Estrat√©gia de Identifica√ß√£o:**
- Se pessoa est√° cadastrada na Midiaz: usar CPF como identificador principal
- Se pessoa n√£o est√° cadastrada: usar `person_id` gerado (hash de face ou posi√ß√£o)
- Garantir que mesmo pessoa em m√∫ltiplas fotos = 1 registro na tabela

#### 4.2.4. Tabela: `photo_persons`

Associa√ß√£o entre fotos e pessoas detectadas na foto. Uma foto pode ter m√∫ltiplas pessoas.

```sql
CREATE TABLE photo_persons (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    photo_id UUID NOT NULL REFERENCES photos_raw(id) ON DELETE CASCADE,
    person_id UUID NOT NULL, -- Refer√™ncia a event_persons.person_id
    event_id UUID NOT NULL REFERENCES events(id) ON DELETE CASCADE,
    person_bounding_box JSONB NOT NULL, -- {x, y, width, height} da pessoa na foto
    detection_confidence DECIMAL(5,4), -- Confian√ßa da detec√ß√£o de pessoa
    created_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(photo_id, person_id) -- Uma pessoa aparece uma vez por foto
);

CREATE INDEX idx_photo_persons_photo ON photo_persons(photo_id);
CREATE INDEX idx_photo_persons_person ON photo_persons(person_id);
CREATE INDEX idx_photo_persons_event ON photo_persons(event_id);
```

#### 4.2.5. Tabela: `raw_detections`

Detec√ß√µes brutas de itens (marcas e produtos) da API de vis√£o computacional. **IMPORTANTE:** Estas detec√ß√µes ainda n√£o est√£o associadas a pessoas.

```sql
CREATE TABLE raw_detections (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_id UUID NOT NULL REFERENCES events(id) ON DELETE CASCADE,
    photo_id UUID NOT NULL REFERENCES photos_raw(id) ON DELETE CASCADE,
    photo_s3_key VARCHAR(500) NOT NULL,
    detection_type VARCHAR(50) NOT NULL CHECK (detection_type IN ('brand', 'product', 'person')),
    detected_label VARCHAR(200) NOT NULL, -- Nome bruto da API
    confidence_score DECIMAL(5,4) NOT NULL CHECK (confidence_score >= 0 AND confidence_score <= 1),
    bounding_box JSONB NOT NULL, -- {x, y, width, height} - OBRIGAT√ìRIO para associa√ß√£o
    raw_response JSONB, -- Resposta completa da API para debug
    model_version VARCHAR(50), -- Vers√£o do modelo usado
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_detections_event ON raw_detections(event_id);
CREATE INDEX idx_detections_photo ON raw_detections(photo_id);
CREATE INDEX idx_detections_type ON raw_detections(detection_type);
CREATE INDEX idx_detections_label ON raw_detections(detected_label);
CREATE INDEX idx_detections_confidence ON raw_detections(confidence_score);
```

**Nota:** Bounding boxes s√£o **obrigat√≥rios** no MVP para permitir associa√ß√£o correta de itens a pessoas.

#### 4.2.6. Tabela: `person_items`

**Tabela central que associa itens detectados (marcas e produtos) √†s pessoas corretas.** Cada registro representa um tipo de produto de uma pessoa em um evento espec√≠fico.

**Regras de Neg√≥cio:**
- Cada pessoa pode ter apenas **um registro por tipo de produto** no mesmo evento (ex: uma pessoa n√£o pode ter dois t√™nis no mesmo evento)
- Campos **sempre preenchidos**: `event_id`, `person_id`, `product_type`, `brand`
- Campo **opcional**: `product_name` (s√≥ preenchido quando modelo foi treinado para identificar produto espec√≠fico)

```sql
CREATE TABLE person_items (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_id UUID NOT NULL REFERENCES events(id) ON DELETE CASCADE,
    person_id UUID NOT NULL, -- Refer√™ncia a event_persons.person_id
    
    -- SEMPRE PREENCHIDOS
    product_type VARCHAR(50) NOT NULL CHECK (product_type IN ('t√™nis', 'camiseta', 'short', '√≥culos', 'bon√©')),
    brand VARCHAR(200) NOT NULL CHECK (brand IN ('Nike', 'Adidas', 'Mizuno', 'Track&Field', 'Asics', 'Olympikus')),
    
    -- OPCIONAL (s√≥ se modelo foi treinado para identificar produto espec√≠fico)
    product_name VARCHAR(200), -- Nome exato do produto (ex: "Air Zoom Pegasus", "T√™nis Corre 4")
    
    created_at TIMESTAMP DEFAULT NOW(),
    
    -- Constraint: uma pessoa n√£o pode ter o mesmo tipo de produto duplicado no mesmo evento
    UNIQUE(event_id, person_id, product_type)
);

CREATE INDEX idx_person_items_event ON person_items(event_id);
CREATE INDEX idx_person_items_person ON person_items(person_id);
CREATE INDEX idx_person_items_brand ON person_items(brand);
CREATE INDEX idx_person_items_product ON person_items(product_type);
CREATE INDEX idx_person_items_event_brand ON person_items(event_id, brand);
```

**Marcas Permitidas:**
- Nike
- Adidas
- Mizuno
- Track&Field
- Asics
- Olympikus

**Tipos de Produto Permitidos:**
- t√™nis
- camiseta
- short
- √≥culos
- bon√©

**Produtos Espec√≠ficos Treinados (exemplos):**
- Nike: "Air Zoom Pegasus" (t√™nis)
- Adidas: "Ultraboost 22" (t√™nis)
- Mizuno: "Wave Rider" (t√™nis)
- Track&Field: "Corre 4" (t√™nis)
- Asics: "Gel-Nimbus" (t√™nis)
- Olympikus: "Corre 3" (t√™nis)

**Nota:** A tabela `extracted_items` foi substitu√≠da por `person_items`, que j√° cont√©m a associa√ß√£o pessoa-item. Esta mudan√ßa garante que cada item detectado est√° corretamente associado √† pessoa que o est√° usando.

#### 4.2.8. Tabela: `brand_event_summary`

M√©tricas agregadas por marca e evento (view materializada). **Atualizada para usar `person_items`.**

```sql
CREATE MATERIALIZED VIEW brand_event_summary AS
SELECT 
    e.id as event_id,
    e.event_name,
    e.event_date,
    pi.brand,
    COUNT(DISTINCT pi.person_id) as persons_with_brand, -- Pessoas √∫nicas com a marca
    COUNT(DISTINCT pi.id) as total_items,
    ROUND(
        100.0 * COUNT(DISTINCT pi.id) / 
        NULLIF((SELECT COUNT(*) FROM person_items WHERE event_id = e.id), 0),
        2
    ) as brand_share_percent,
    ROUND(
        100.0 * COUNT(DISTINCT pi.person_id) / 
        NULLIF((SELECT COUNT(DISTINCT person_id) FROM event_persons WHERE event_id = e.id), 0),
        2
    ) as person_coverage_percent
FROM events e
JOIN person_items pi ON pi.event_id = e.id
WHERE pi.brand IS NOT NULL
GROUP BY e.id, e.event_name, e.event_date, pi.brand;

CREATE UNIQUE INDEX idx_brand_summary_unique ON brand_event_summary(event_id, brand);
CREATE INDEX idx_brand_summary_event ON brand_event_summary(event_id);
CREATE INDEX idx_brand_summary_brand ON brand_event_summary(brand);
```

**Refresh da View:**
```sql
-- Atualizar ap√≥s processamento completo
REFRESH MATERIALIZED VIEW CONCURRENTLY brand_event_summary;
```

#### 4.2.8. Tabela: `product_event_summary`

M√©tricas agregadas por produto e evento. **Atualizada para usar `person_items`.**

```sql
CREATE MATERIALIZED VIEW product_event_summary AS
SELECT 
    e.id as event_id,
    e.event_name,
    pi.product_type,
    COUNT(DISTINCT pi.person_id) as persons_with_product, -- Pessoas √∫nicas com o produto
    COUNT(DISTINCT pi.id) as total_items,
    ROUND(
        100.0 * COUNT(DISTINCT pi.id) / 
        NULLIF((SELECT COUNT(*) FROM person_items WHERE event_id = e.id), 0),
        2
    ) as product_share_percent
FROM events e
JOIN person_items pi ON pi.event_id = e.id
WHERE pi.product_type IS NOT NULL
GROUP BY e.id, e.event_name, pi.product_type;

CREATE UNIQUE INDEX idx_product_summary_unique ON product_event_summary(event_id, product_type);
```

#### 4.2.9. Tabela: `report_metadata`

Metadados dos relat√≥rios gerados.

```sql
CREATE TABLE report_metadata (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_id UUID NOT NULL REFERENCES events(id) ON DELETE CASCADE,
    report_type VARCHAR(50) NOT NULL CHECK (report_type IN ('pdf', 'dashboard', 'api')),
    s3_key VARCHAR(500), -- Chave S3 do PDF (se aplic√°vel)
    s3_url VARCHAR(1000), -- URL assinada (tempor√°ria)
    generated_at TIMESTAMP DEFAULT NOW(),
    llm_model_version VARCHAR(50), -- Vers√£o do LLM usado
    llm_prompt_version VARCHAR(50), -- Vers√£o do prompt
    metadata JSONB -- Dados adicionais do relat√≥rio
);

CREATE INDEX idx_reports_event ON report_metadata(event_id);
CREATE INDEX idx_reports_type ON report_metadata(report_type);
```

### 4.3. M√©tricas Calculadas

#### 4.3.1. Share de Marca (Brand Share)

**F√≥rmula:**
```
Brand Share (%) = (Detec√ß√µes da Marca / Total de Detec√ß√µes) √ó 100
```

**Exemplo:**
- Total de detec√ß√µes: 10.000
- Detec√ß√µes Nike: 3.200
- **Nike Share: 32%**

**Implementa√ß√£o SQL:**
```sql
SELECT 
    brand,
    COUNT(DISTINCT person_id) as persons_count, -- Pessoas √∫nicas
    COUNT(*) as items_count,
    ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 2) as share_percent
FROM person_items
WHERE event_id = '...'
GROUP BY brand
ORDER BY share_percent DESC;
```

#### 4.3.2. Volume Absoluto

**Defini√ß√£o:** N√∫mero total de apari√ß√µes de uma marca no evento.

**M√©tricas:**
- Total de detec√ß√µes
- Total de fotos com a marca
- Total de atletas √∫nicos (estimado)

#### 4.3.3. Predomin√¢ncia por Categoria

**Defini√ß√£o:** Qual categoria de produto tem maior presen√ßa.

**Exemplo:**
- T√™nis: 64% das detec√ß√µes
- Camisetas: 28%
- Acess√≥rios: 8%

#### 4.3.4. Ranking de Produtos

**Ordena√ß√£o:** Por volume absoluto ou share.

**Exemplo:**
1. T√™nis Nike (2.500 detec√ß√µes, 25%)
2. T√™nis Adidas (2.000 detec√ß√µes, 20%)
3. Camiseta Nike (1.800 detec√ß√µes, 18%)

#### 4.3.5. Distribui√ß√£o por Faixa Et√°ria (v2)

**Status:** ‚ùå Fora do MVP

**Para v2:** Usar AWS Rekognition Face Analysis para estimar idade.

#### 4.3.6. Comparativo entre Marcas

**M√©tricas:**
- Share relativo (%)
- Volume absoluto
- Confian√ßa m√©dia
- Cobertura de fotos (em quantas fotos aparece)

**Visualiza√ß√£o:** Tabela comparativa com ranking.

---

## 5. Pipeline de Processamento

### 5.1. Passo a Passo Detalhado

#### 5.1.1. Ingest√£o

**Objetivo:** Carregar fotos e metadados do evento no sistema.

**Input:**
- Fotos no S3 (bucket: `midiaz-raw-images`)
- Metadados do evento (JSON via API ou arquivo)

**Processo:**
1. Valida√ß√£o de formato (JPEG, PNG)
2. Valida√ß√£o de tamanho (m√≠n: 100x100px, m√°x: 10MB)
3. Registro no banco (`photos_raw`)
4. Trigger de processamento

**C√≥digo Exemplo:**
```python
async def ingest_event(event_metadata: EventMetadata, s3_prefix: str):
    # 1. Criar evento no banco
    event = await event_service.create(event_metadata)
    
    # 2. Listar imagens no S3
    images = await s3_service.list_images(s3_prefix)
    
    # 3. Validar e registrar cada imagem
    for image_key in images:
        metadata = await s3_service.get_metadata(image_key)
        photo = await photo_service.create({
            "event_id": event.id,
            "s3_key": image_key,
            "file_size": metadata["size"],
            "image_width": metadata.get("width"),
            "image_height": metadata.get("height")
        })
    
    # 4. Atualizar total de fotos
    await event_service.update_photo_count(event.id)
    
    # 5. Disparar processamento
    await trigger_processing(event.id)
    
    return event
```

#### 5.1.2. Pr√©-processamento

**Objetivo:** Otimizar imagens para API de vis√£o.

**Processo:**
1. Download da imagem do S3
2. Redimensionamento (1024x1024px, mant√©m aspect ratio)
3. Compress√£o JPEG (qualidade 85%)
4. Convers√£o para RGB
5. Upload para S3 processado (opcional, ou processar em mem√≥ria)

**C√≥digo:**
```python
async def preprocess_image(image_bytes: bytes) -> bytes:
    img = Image.open(io.BytesIO(image_bytes))
    img = img.convert('RGB')
    img.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
    
    output = io.BytesIO()
    img.save(output, format='JPEG', quality=85, optimize=True)
    return output.getvalue()
```

#### 5.1.3. Infer√™ncia de Vis√£o Computacional

**Objetivo:** Detectar pessoas, marcas e produtos nas imagens.

**Processo:**
1. Agrupar imagens em batches de 10
2. Chamar API de vis√£o para detectar:
   - Pessoas (com bounding boxes)
   - Marcas (com bounding boxes)
   - Produtos (com bounding boxes)
3. Parse da resposta
4. Filtrar por confian√ßa m√≠nima (threshold: 0.6)
5. Salvar detec√ß√µes brutas no banco

**C√≥digo:**
```python
async def process_vision_batch(photos: List[Photo]) -> Tuple[List[PersonDetection], List[ItemDetection]]:
    person_detections = []
    item_detections = []
    
    for photo in photos:
        image_bytes = await s3_service.download(photo.s3_key)
        processed_image = await preprocess_image(image_bytes)
        
        # Chamada √† API - detectar pessoas e itens
        response = await vision_service.detect_all(processed_image)
        
        # Parse pessoas
        for person in response.persons:
            if person.confidence >= 0.6:
                person_detections.append(PersonDetection(
                    event_id=photo.event_id,
                    photo_id=photo.id,
                    bounding_box=person.bbox,
                    confidence_score=person.confidence
                ))
        
        # Parse itens (marcas e produtos)
        for item in response.items:
            if item.confidence >= 0.6:
                item_detections.append(RawDetection(
                    event_id=photo.event_id,
                    photo_id=photo.id,
                    detection_type=item.type,  # 'brand' ou 'product'
                    detected_label=item.label,
                    confidence_score=item.confidence,
                    bounding_box=item.bbox,  # OBRIGAT√ìRIO
                    raw_response=response.raw
                ))
    
    # Salvar em lote
    await db_writer.save_persons_batch(person_detections)
    await db_writer.save_detections_batch(item_detections)
    
    return person_detections, item_detections
```

#### 5.1.4. Associa√ß√£o de Itens a Pessoas

**Objetivo:** Associar itens detectados (marcas e produtos) √†s pessoas corretas na foto.

**Processo:**
1. Para cada foto, buscar pessoas e itens detectados
2. Associar cada item √† pessoa mais pr√≥xima usando algoritmo de proximidade espacial
3. Validar associa√ß√µes (threshold de confian√ßa)
4. Criar registros em `person_items` (tabela final)

**C√≥digo:**
```python
async def associate_items_to_persons(photo_id: UUID, event_id: UUID):
    # Buscar pessoas e itens da foto
    persons = await db_service.get_persons_in_photo(photo_id)
    items = await db_service.get_items_in_photo(photo_id)
    
    # Associar itens a pessoas
    associations = await association_service.associate(persons, items)
    
    # Normalizar marcas e validar produtos
    person_items = []
    for assoc in associations:
        if assoc.person_id and assoc.association_confidence >= 0.5:
            # Normalizar marca (se aplic√°vel)
            normalized_brand = None
            if assoc.item.detection_type == 'brand':
                normalized_brand = await brand_normalizer.normalize(assoc.item.detected_label)
            elif assoc.item.detection_type == 'product' and assoc.item.brand:
                normalized_brand = await brand_normalizer.normalize(assoc.item.brand)
            
            # Validar categoria de produto
            product_type = None
            if assoc.item.detection_type == 'product':
                product_type = await product_classifier.classify(assoc.item.detected_label)
            
            person_items.append(PersonItem(
                event_id=event_id,
                person_id=assoc.person_id,
                photo_id=photo_id,
                item_type=assoc.item.detection_type,
                brand=assoc.item.detected_label if assoc.item.detection_type == 'brand' else assoc.item.brand,
                product_type=product_type,
                normalized_brand=normalized_brand,
                confidence_score=assoc.item.confidence_score,
                item_bounding_box=assoc.item.bbox,
                person_bounding_box=assoc.person.bbox,
                association_confidence=assoc.association_confidence,
                source_detection_id=assoc.item.id
            ))
    
    # Salvar associa√ß√µes
    await db_writer.save_person_items(person_items)
    
    # Atualizar contadores de pessoas
    await update_person_photo_count(event_id, associations)
    
    return person_items
```

#### 5.1.5. Enriquecimento com Dados Cadastrais

**Objetivo:** Enriquecer registros de pessoas com dados cadastrais (CPF, idade, g√™nero) quando dispon√≠veis.

**Processo:**
1. Para cada pessoa no evento, verificar se tem CPF
2. Se tiver CPF, buscar dados cadastrais no sistema B2C
3. Atualizar registro em `event_persons` com idade, g√™nero, etc.

**C√≥digo:**
```python
async def enrich_persons_with_cadastral_data(event_id: UUID):
    persons = await db_service.get_persons_by_event(event_id)
    
    for person in persons:
        if person.cpf:
            # Buscar dados cadastrais no sistema B2C
            cadastral_data = await b2c_service.get_person_data(person.cpf)
            
            if cadastral_data:
                await db_service.update_person(
                    person.id,
                    age=cadastral_data.age,
                    gender=cadastral_data.gender,
                    is_registered=True
                )
```

#### 5.1.6. Agrega√ß√£o

**Objetivo:** Calcular m√©tricas agregadas por evento.

**Processo:**
1. Agregar por marca (share, volume, confian√ßa m√©dia)
2. Agregar por produto (share, volume)
3. Calcular rankings
4. Atualizar views materializadas

**C√≥digo:**
```python
async def aggregate_event_metrics(event_id: UUID):
    # Agregar marcas
    brand_metrics = await aggregation_service.aggregate_brands(event_id)
    
    # Agregar produtos
    product_metrics = await aggregation_service.aggregate_products(event_id)
    
    # Atualizar views
    await db_service.refresh_materialized_views()
    
    # Atualizar status do evento
    await event_service.update_status(event_id, 'completed')
    
    return {
        "brand_metrics": brand_metrics,
        "product_metrics": product_metrics
    }
```

#### 5.1.7. Gera√ß√£o do Dataset Final

**Objetivo:** Criar tabelas anal√≠ticas prontas para consumo.

**Processo:**
1. Views materializadas j√° criadas (`brand_event_summary`, `product_event_summary`)
2. Exportar para CSV/Parquet (opcional)
3. Disponibilizar via API

#### 5.1.8. Gera√ß√£o do Relat√≥rio

**Objetivo:** Gerar relat√≥rio PDF com insights em linguagem natural.

**Processo:**
1. Buscar m√©tricas agregadas
2. Construir prompt para LLM
3. Chamar OpenAI API
4. Gerar PDF com template
5. Upload para S3
6. Registrar metadados

**C√≥digo:**
```python
async def generate_report(event_id: UUID) -> str:
    # 1. Buscar dados
    event = await event_service.get(event_id)
    brand_metrics = await aggregation_service.get_brand_metrics(event_id)
    product_metrics = await aggregation_service.get_product_metrics(event_id)
    
    # 2. Construir prompt
    prompt = prompt_builder.build_report_prompt(
        event=event,
        brands=brand_metrics,
        products=product_metrics
    )
    
    # 3. Chamar LLM
    llm_response = await llm_service.generate(prompt)
    
    # 4. Gerar PDF
    pdf_bytes = await pdf_generator.generate(
        event=event,
        narrative=llm_response.text,
        metrics=brand_metrics,
        charts=await chart_service.export_charts(event_id)
    )
    
    # 5. Upload S3
    s3_key = f"reports/{event_id}/report_{datetime.now().isoformat()}.pdf"
    await s3_service.upload(s3_key, pdf_bytes)
    
    # 6. Registrar
    await report_service.create({
        "event_id": event_id,
        "s3_key": s3_key,
        "report_type": "pdf"
    })
    
    return s3_key
```

### 5.2. Tecnologias Sugeridas

#### 5.2.1. Stack MVP Recomendada

**Decis√£o:** **AWS Serverless + PostgreSQL (RDS)**

| Componente | Tecnologia | Justificativa |
|------------|------------|---------------|
| **Processamento** | AWS Lambda | Custo-efetivo, escala autom√°tica, sem gerenciamento de servidor |
| **Orquestra√ß√£o** | EventBridge + Step Functions | Gerenciamento de fluxo complexo, retry autom√°tico |
| **Armazenamento Imagens** | S3 | Durabilidade, baixo custo, integra√ß√£o nativa |
| **Banco de Dados** | PostgreSQL (RDS) | Queries anal√≠ticas, relacionamentos, views materializadas |
| **API** | FastAPI (EC2/Fargate) | Async, f√°cil deploy, documenta√ß√£o autom√°tica |
| **Dashboard** | Metabase (EC2) | Open source, f√°cil conex√£o PostgreSQL |
| **LLM** | OpenAI API | Alta qualidade, f√°cil integra√ß√£o |

**Custo Estimado MVP:**
- Lambda: $0.20 por 1M requisi√ß√µes + $0.0000166667/GB-segundo
- RDS t3.medium: ~$70/m√™s
- S3: ~$0.023/GB armazenado
- OpenAI API: ~$0.03-0.06 por relat√≥rio
- **Total: ~$100-150/m√™s** (com uso moderado)

#### 5.2.2. Alternativa: Stack Local (Desenvolvimento)

Para desenvolvimento e testes locais:

```yaml
# docker-compose.yml
version: '3.8'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: midiaz_b2b
      POSTGRES_USER: midiaz
      POSTGRES_PASSWORD: midiaz123
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  minio:
    image: minio/minio
    command: server /data
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
  
  metabase:
    image: metabase/metabase
    ports:
      - "3000:3000"
    depends_on:
      - postgres
    environment:
      MB_DB_TYPE: postgres
      MB_DB_DBNAME: metabase
      MB_DB_PORT: 5432
      MB_DB_USER: midiaz
      MB_DB_PASS: midiaz123
      MB_DB_HOST: postgres

volumes:
  postgres_data:
```

**Uso:** Desenvolvimento local, testes, prototipagem r√°pida.

---

## 6. Plano de Evolu√ß√£o T√©cnica

### 6.1. v1 - Modelo Multi-Evento

**Objetivo:** Processar m√∫ltiplos eventos e comparar.

**Novas Features:**
- Compara√ß√£o entre eventos
- Tend√™ncias temporais
- Dashboard multi-evento
- API de compara√ß√£o

**Mudan√ßas T√©cnicas:**
- Adicionar tabela `event_comparisons`
- Views agregadas por per√≠odo
- Cache de m√©tricas (Redis)

### 6.2. v2 - Modelo Multi-Marca, Multi-Produto Detalhado

**Objetivo:** Detec√ß√£o mais granular e precisa.

**Novas Features:**
- Bounding boxes precisos
- Detec√ß√£o de modelos espec√≠ficos (ex: "Nike Air Max 270")
- Classifica√ß√£o de contexto (in√≠cio/fim de prova)
- Estimativa de idade/g√™nero (opcional)

**Mudan√ßas T√©cnicas:**
- Modelo customizado Rekognition treinado
- Fine-tuning cont√≠nuo
- Pipeline de anota√ß√£o de dados

### 6.3. v3 - API de Insights em Tempo Real

**Objetivo:** Processamento em tempo real durante eventos.

**Novas Features:**
- Processamento streaming (fotos chegam e s√£o processadas imediatamente)
- API WebSocket para atualiza√ß√µes em tempo real
- Dashboard com atualiza√ß√£o live
- Alertas de presen√ßa de marca

**Mudan√ßas T√©cnicas:**
- Kinesis Data Streams para ingest√£o
- Lambda com concurrency > 1
- WebSocket API (API Gateway)
- Cache Redis para m√©tricas em tempo real

### 6.4. v4 - √çndice Propriet√°rio de Marca

**Objetivo:** Criar √≠ndice nacional de presen√ßa de marca esportiva.

**Novas Features:**
- Agrega√ß√£o nacional de dados
- Ranking de marcas por regi√£o
- Tend√™ncias de mercado
- API p√∫blica de consulta

**Mudan√ßas T√©cnicas:**
- Data warehouse (Redshift ou BigQuery)
- ETL di√°rio/semanal
- API p√∫blica com rate limiting
- Autentica√ß√£o OAuth2

### 6.5. v5 - Infraestrutura Nacional de Intelig√™ncia Esportiva

**Objetivo:** Plataforma completa de intelig√™ncia esportiva.

**Novas Features:**
- M√∫ltiplos tipos de eventos (n√£o s√≥ corrida)
- An√°lise preditiva
- Recomenda√ß√µes de ativa√ß√£o
- Integra√ß√£o com CRMs

**Mudan√ßas T√©cnicas:**
- Arquitetura multi-tenant
- Machine Learning pr√≥prio (SageMaker)
- Microservi√ßos especializados
- Infraestrutura global (multi-region)

---

## 7. Roadmap de Desenvolvimento

### 7.1. Sprint 1 (2 semanas) - Ingest√£o + Dataset Bruto

**Objetivos:**
- Setup de infraestrutura b√°sica
- Ingest√£o de fotos do S3
- Registro de metadados do evento
- Valida√ß√£o de imagens

**Entregas:**
- [ ] Setup PostgreSQL (RDS ou local)
- [ ] Setup S3 bucket
- [ ] API FastAPI b√°sica (criar evento, listar eventos)
- [ ] M√≥dulo de ingest√£o (`ingestion/`)
- [ ] Tabelas do banco (`events`, `photos_raw`)
- [ ] Testes unit√°rios de ingest√£o

**Crit√©rio de Sucesso:**
- Consegue criar evento e registrar 100+ fotos
- Dados persistidos corretamente no banco

### 7.2. Sprint 2 (2 semanas) - Pipeline Completo + Extra√ß√£o

**Objetivos:**
- Integra√ß√£o com API de vis√£o
- Processamento batch de imagens
- Extra√ß√£o de marcas e produtos
- Persist√™ncia de detec√ß√µes

**Entregas:**
- [ ] M√≥dulo de pr√©-processamento (`preprocessing/`)
- [ ] Integra√ß√£o AWS Rekognition ou OpenAI Vision
- [ ] M√≥dulo de extra√ß√£o (`vision_extraction/`)
- [ ] Tabela `raw_detections`
- [ ] Processamento batch (Lambda ou script)
- [ ] Filtro por confian√ßa m√≠nima
- [ ] Testes de integra√ß√£o com API de vis√£o

**Crit√©rio de Sucesso:**
- Processa 1000+ imagens e extrai marcas/produtos
- Detec√ß√µes salvas no banco com confian√ßa > 0.6

### 7.3. Sprint 3 (2 semanas) - Dataset Anal√≠tico + M√©tricas

**Objetivos:**
- Normaliza√ß√£o de marcas
- Enriquecimento de dados
- Agrega√ß√£o de m√©tricas
- Views materializadas

**Entregas:**
- [ ] M√≥dulo de enriquecimento (`data_enrichment/`)
- [ ] Tabela `brand_normalization` (seed com marcas principais)
- [ ] Tabela `extracted_items`
- [ ] M√≥dulo de agrega√ß√£o (`aggregation/`)
- [ ] Views materializadas (`brand_event_summary`, `product_event_summary`)
- [ ] C√°lculo de shares e rankings
- [ ] Testes de agrega√ß√£o

**Crit√©rio de Sucesso:**
- M√©tricas calculadas corretamente
- Share de marca calculado e validado manualmente

### 7.4. Sprint 4 (2 semanas) - Relat√≥rio Anal√≠tico + Valida√ß√£o

**Objetivos:**
- Gera√ß√£o de relat√≥rio PDF com LLM
- Dashboard Metabase
- Valida√ß√£o com evento real
- Ajustes de qualidade

**Entregas:**
- [ ] M√≥dulo de gera√ß√£o de relat√≥rio (`report_generator/`)
- [ ] Integra√ß√£o OpenAI API
- [ ] Template de PDF
- [ ] Dashboard Metabase configurado
- [ ] Visualiza√ß√µes principais (4-6 gr√°ficos)
- [ ] Processamento de evento real (pilot)
- [ ] Valida√ß√£o de qualidade (precis√£o, recall)
- [ ] Ajustes baseados em feedback

**Crit√©rio de Sucesso:**
- Relat√≥rio PDF gerado com insights coerentes
- Dashboard funcional e explor√°vel
- Evento real processado com sucesso

### 7.5. Sprint 5 (1-2 semanas) - Ajustes + Entrega Final

**Objetivos:**
- Corre√ß√£o de bugs
- Otimiza√ß√µes de performance
- Documenta√ß√£o completa
- Deploy em produ√ß√£o

**Entregas:**
- [ ] Corre√ß√£o de bugs identificados
- [ ] Otimiza√ß√£o de queries (√≠ndices)
- [ ] Cache de resultados (se necess√°rio)
- [ ] Documenta√ß√£o t√©cnica completa
- [ ] README, CONTRIBUTING, BUILD.md
- [ ] Diagramas C4 atualizados
- [ ] Deploy em produ√ß√£o (AWS)
- [ ] Testes end-to-end
- [ ] Apresenta√ß√£o final

**Crit√©rio de Sucesso:**
- Sistema funcional em produ√ß√£o
- Documenta√ß√£o completa e clara
- Apresenta√ß√£o bem-sucedida

---

## 8. Riscos T√©cnicos e Mitiga√ß√µes

### 8.1. Erros do Modelo de Vis√£o

**Risco:** Modelo detecta marcas incorretas ou n√£o detecta marcas presentes.

**Mitiga√ß√£o:**
- **Threshold de confian√ßa:** Filtrar detec√ß√µes com confian√ßa < 0.6
- **Valida√ß√£o manual:** Amostra de 100 imagens validadas manualmente
- **Normaliza√ß√£o de marcas:** Mapear varia√ß√µes ("nike", "Nike", "NIKE") para "Nike"
- **Feedback loop:** Registrar falsos positivos/negativos para melhorar modelo

**Monitoramento:**
- Dashboard de qualidade (confian√ßa m√©dia, distribui√ß√£o)
- Alertas se confian√ßa m√©dia < 0.7

### 8.2. Varia√ß√£o de Ilumina√ß√£o

**Risco:** Imagens com baixa ilumina√ß√£o reduzem precis√£o.

**Mitiga√ß√£o:**
- **Pr√©-processamento:** Ajuste de brilho/contraste autom√°tico
- **Normaliza√ß√£o:** Histogram equalization
- **M√∫ltiplas tentativas:** Se confian√ßa baixa, tentar com imagem ajustada

**C√≥digo:**
```python
from PIL import ImageEnhance

def enhance_image(image: Image) -> Image:
    enhancer = ImageEnhance.Brightness(image)
    image = enhancer.enhance(1.2)  # Aumenta brilho 20%
    enhancer = ImageEnhance.Contrast(image)
    image = enhancer.enhance(1.1)  # Aumenta contraste 10%
    return image
```

### 8.3. Baixa Qualidade da Imagem

**Risco:** Imagens muito pequenas ou comprimidas reduzem detec√ß√£o.

**Mitiga√ß√£o:**
- **Valida√ß√£o na ingest√£o:** Rejeitar imagens < 100x100px
- **Upscaling:** Usar super-resolution (opcional, v2)
- **M√∫ltiplas escalas:** Tentar detec√ß√£o em diferentes tamanhos

**Valida√ß√£o:**
```python
def validate_image_quality(image_bytes: bytes) -> bool:
    img = Image.open(io.BytesIO(image_bytes))
    width, height = img.size
    
    if width < 100 or height < 100:
        return False
    
    if len(image_bytes) < 10 * 1024:  # < 10KB
        return False
    
    return True
```

### 8.4. Fotos sem Marca Aparente

**Risco:** Muitas fotos n√£o t√™m marca vis√≠vel (falsos negativos esperados).

**Mitiga√ß√£o:**
- **Expectativa realista:** N√£o esperar 100% de detec√ß√£o
- **M√©tricas de cobertura:** Reportar % de fotos com pelo menos 1 detec√ß√£o
- **Filtro de contexto:** Priorizar fotos de atletas (n√£o paisagem)

**M√©trica:**
```
Photo Coverage = (Fotos com detec√ß√£o / Total de fotos) √ó 100
Meta: > 40% de cobertura
```

### 8.5. Classifica√ß√£o Amb√≠gua

**Risco:** Produto pode ser classificado incorretamente (ex: "t√™nis" vs "sapato").

**Mitiga√ß√£o:**
- **Categorias bem definidas:** Lista fixa de categorias v√°lidas
- **Valida√ß√£o p√≥s-processamento:** Filtrar categorias inv√°lidas
- **Confian√ßa por categoria:** Threshold diferente por tipo de produto

**Categorias MVP:**
```python
VALID_PRODUCT_TYPES = [
    "t√™nis", "camiseta", "bon√©", "√≥culos", 
    "short", "meia", "rel√≥gio", "mochila"
]
```

### 8.6. Lat√™ncia de Processamento

**Risco:** Processar 10k+ imagens pode levar horas.

**Mitiga√ß√£o:**
- **Processamento paralelo:** M√∫ltiplas Lambdas em paralelo (com rate limiting)
- **Otimiza√ß√£o de batch:** Processar 10 imagens por requisi√ß√£o
- **Status ass√≠ncrono:** API retorna imediatamente, cliente consulta status
- **Notifica√ß√£o:** Webhook ou email quando processamento completo

**Estimativa:**
- 1 imagem = ~2-3 segundos (API + processamento)
- 10.000 imagens = ~5-8 horas (sequencial)
- Com paralelismo (10 workers): ~30-50 minutos

**C√≥digo de Paralelismo:**
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def process_event_parallel(event_id: UUID, max_workers: int = 10):
    photos = await photo_service.list_pending(event_id)
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        loop = asyncio.get_event_loop()
        tasks = [
            loop.run_in_executor(executor, process_photo, photo)
            for photo in photos
        ]
        await asyncio.gather(*tasks)
```

### 8.7. Custos de API

**Risco:** Custos de API de vis√£o podem explodir com volume alto.

**Mitiga√ß√£o:**
- **Cache de resultados:** N√£o reprocessar mesma imagem
- **Amostragem:** Processar amostra representativa (ex: 20% das fotos)
- **Otimiza√ß√£o de tamanho:** Reduzir tamanho da imagem antes do envio
- **Budget alerts:** Configurar alertas AWS/OpenAI para limites

**C√°lculo de Custo:**
- OpenAI Vision: $0.01-0.03/imagem
- 10.000 imagens = $100-300
- Com amostragem 20%: $20-60

**C√≥digo de Cache:**
```python
from functools import lru_cache
import hashlib

def get_image_hash(image_bytes: bytes) -> str:
    return hashlib.md5(image_bytes).hexdigest()

@lru_cache(maxsize=1000)
async def get_cached_detection(image_hash: str):
    # Verifica se j√° processou esta imagem
    cached = await cache.get(f"detection:{image_hash}")
    if cached:
        return cached
    return None
```

### 8.8. Escalabilidade do Banco

**Risco:** PostgreSQL pode ficar lento com milh√µes de detec√ß√µes.

**Mitiga√ß√£o:**
- **√çndices estrat√©gicos:** Criar √≠ndices em colunas de busca frequente
- **Particionamento:** Particionar tabelas por evento ou data (v2)
- **Views materializadas:** Pr√©-calcular agrega√ß√µes
- **Archiving:** Mover dados antigos para S3 (v2)

**√çndices Cr√≠ticos:**
```sql
CREATE INDEX idx_detections_event_type ON raw_detections(event_id, detection_type);
CREATE INDEX idx_detections_brand ON raw_detections(detected_label) WHERE detection_type = 'brand';
CREATE INDEX idx_items_event_brand ON extracted_items(event_id, normalized_brand);
```

---

## 9. Checklist Final

### 9.1. Funcionalidades Core

- [ ] Ingest√£o de fotos do S3 funcional
- [ ] Metadados do evento registrados corretamente
- [ ] Pr√©-processamento de imagens (resize, compress√£o)
- [ ] Integra√ß√£o com API de vis√£o (Rekognition ou OpenAI)
- [ ] Detec√ß√£o de marcas com confian√ßa > 0.6
- [ ] Detec√ß√£o de produtos categorizados
- [ ] Normaliza√ß√£o de marcas funcionando
- [ ] Agrega√ß√£o de m√©tricas (share, volume, ranking)
- [ ] Gera√ß√£o de relat√≥rio PDF com LLM
- [ ] Dashboard Metabase com visualiza√ß√µes principais

### 9.2. Qualidade de Dados

- [ ] Valida√ß√£o de imagens na ingest√£o
- [ ] Filtro de confian√ßa aplicado
- [ ] Normaliza√ß√£o de marcas testada
- [ ] M√©tricas calculadas corretamente (valida√ß√£o manual)
- [ ] Sem dados duplicados
- [ ] Integridade referencial (foreign keys)

### 9.3. Performance

- [ ] Processamento de 1000+ imagens em < 2 horas
- [ ] Queries de agrega√ß√£o < 5 segundos
- [ ] API responde em < 500ms (endpoints de consulta)
- [ ] Gera√ß√£o de relat√≥rio PDF < 30 segundos
- [ ] Dashboard carrega em < 3 segundos

### 9.4. Infraestrutura

- [ ] PostgreSQL configurado e acess√≠vel
- [ ] S3 buckets criados e configurados
- [ ] Lambda functions deployadas (se aplic√°vel)
- [ ] API FastAPI rodando e acess√≠vel
- [ ] Metabase configurado e conectado ao banco
- [ ] Vari√°veis de ambiente configuradas (secrets)
- [ ] Logs centralizados (CloudWatch ou similar)

### 9.5. Seguran√ßa

- [ ] Credenciais em vari√°veis de ambiente (n√£o hardcoded)
- [ ] S3 buckets com acesso restrito
- [ ] API com autentica√ß√£o b√°sica (se necess√°rio)
- [ ] Banco de dados com acesso restrito (security groups)
- [ ] Dados de atletas anonimizados (sem PII)

### 9.6. Documenta√ß√£o

- [ ] README.md completo e atualizado
- [ ] CONTRIBUTING.md com instru√ß√µes de setup
- [ ] BUILD.md com instru√ß√µes de build e deploy
- [ ] Diagramas C4 (Contexto, Cont√™iner, Componente)
- [ ] Documenta√ß√£o de API (Swagger/OpenAPI)
- [ ] Coment√°rios no c√≥digo (docstrings)
- [ ] Changelog ou hist√≥rico de mudan√ßas

### 9.7. Testes

- [ ] Testes unit√°rios para m√≥dulos principais (> 60% cobertura)
- [ ] Testes de integra√ß√£o com API de vis√£o (mocks)
- [ ] Testes end-to-end (processamento completo de evento)
- [ ] Valida√ß√£o manual com evento real
- [ ] Testes de carga (opcional, mas recomendado)

### 9.8. Valida√ß√£o com Stakeholders

- [ ] Evento real processado com sucesso
- [ ] Relat√≥rio PDF gerado e revisado
- [ ] Dashboard explorado por usu√°rio final
- [ ] Feedback coletado e incorporado
- [ ] M√©tricas de qualidade validadas (precis√£o, recall)

---

## 10. Conclus√£o e Pr√≥ximos Passos

### 10.1. Resumo do Plano

Este plano t√©cnico define a arquitetura, design e implementa√ß√£o do **Event Brand Report MVP**, produto anal√≠tico que transforma fotos esportivas em insights sobre presen√ßa de marca. O MVP foca em:

1. **Processamento de 1 evento completo** com detec√ß√£o de marcas e produtos
2. **Gera√ß√£o de m√©tricas agregadas** (share, volume, ranking)
3. **Entrega via dashboard e relat√≥rio PDF** com insights em linguagem natural

**Stack Principal:**
- **Backend:** FastAPI (Python)
- **Vis√£o:** AWS Rekognition ou OpenAI Vision API
- **Banco:** PostgreSQL (RDS)
- **Storage:** S3
- **Dashboard:** Metabase
- **LLM:** OpenAI GPT-4/3.5

**Custo Estimado:** ~$100-150/m√™s (com uso moderado)

**Timeline:** 5 sprints (10-12 semanas)

### 10.2. Pr√≥ximos Passos Imediatos

1. **Setup de Infraestrutura (Semana 1)**
   - Criar conta AWS (se n√£o tiver)
   - Setup RDS PostgreSQL
   - Criar S3 buckets
   - Configurar ambiente local (Docker Compose)

2. **Desenvolvimento Sprint 1 (Semanas 2-3)**
   - Implementar m√≥dulo de ingest√£o
   - Criar tabelas do banco
   - API b√°sica FastAPI
   - Testes unit√°rios

3. **Valida√ß√£o Cont√≠nua**
   - Processar evento piloto pequeno (100-200 imagens)
   - Validar qualidade das detec√ß√µes
   - Ajustar thresholds e normaliza√ß√µes

4. **Documenta√ß√£o Paralela**
   - Manter documenta√ß√£o atualizada
   - Registrar decis√µes t√©cnicas
   - Criar diagramas C4

### 10.3. Decis√µes Pendentes (Resolver nas Primeiras 2 Semanas)

1. **Escolha da API de Vis√£o:**
   - [ ] AWS Rekognition (customizado) ou OpenAI Vision (zero-shot)
   - **Recomenda√ß√£o:** Come√ßar com OpenAI (r√°pido), migrar para Rekognition customizado (v1)

2. **Estrat√©gia de Processamento:**
   - [ ] Lambda serverless ou EC2/Fargate
   - **Recomenda√ß√£o:** Lambda para MVP (custo-efetivo)

3. **Formato de Entrega Principal:**
   - [ ] Dashboard apenas, PDF apenas, ou ambos
   - **Recomenda√ß√£o:** Ambos (dashboard para explora√ß√£o, PDF para apresenta√ß√£o)

### 10.4. M√©tricas de Sucesso do MVP

**T√©cnicas:**
- ‚úÖ Processa 10.000+ imagens sem erros
- ‚úÖ Precis√£o de detec√ß√£o > 70% (valida√ß√£o manual)
- ‚úÖ Tempo de processamento < 8 horas para 10k imagens
- ‚úÖ Relat√≥rio PDF gerado com insights coerentes

**Neg√≥cio:**
- ‚úÖ Relat√≥rio √∫til para organizador de evento
- ‚úÖ Dashboard explor√°vel e intuitivo
- ‚úÖ M√©tricas validadas por stakeholder real
- ‚úÖ Case de sucesso documentado

### 10.5. Contatos e Recursos

**Equipe:**
- Matheus Augusto (L√≠der T√©cnico) - Coordena√ß√£o t√©cnica e arquitetura
- Lu√≠s Felipe Pascoal (Cientista de Dados) - IA e vis√£o computacional
- Rafaela Le√£o (Designer de Produto) - UX e valida√ß√£o com usu√°rios

**Recursos √öteis:**
- [AWS Rekognition Docs](https://docs.aws.amazon.com/rekognition/)
- [OpenAI Vision API](https://platform.openai.com/docs/guides/vision)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Metabase Documentation](https://www.metabase.com/docs/)

---

**Fim do Documento**

*Este plano t√©cnico √© um documento vivo e deve ser atualizado conforme o desenvolvimento avan√ßa e novas decis√µes s√£o tomadas.*

