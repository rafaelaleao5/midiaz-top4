# üìã Plano T√©cnico Completo - Event Brand Report MVP
## Midiaz B2B - Intelig√™ncia Visual para Marketing Esportivo

**Vers√£o:** 1.0  
**Data:** 2025  
**Status:** MVP - Fase de Produ√ß√£o  
**Equipe:** Matheus Augusto (L√≠der T√©cnico), Lu√≠s Felipe Pascoal (Cientista de Dados), Rafaela Le√£o (Designer de Produto)

---

## 1. Resumo Executivo do MVP

### 1.1. Vis√£o Geral do Produto

O **Event Brand Report** √© o produto anal√≠tico central do Midiaz B2B, transformando fotos esportivas brutas em insights estruturados sobre presen√ßa de marca em eventos esportivos. O MVP foca em processar um evento completo (ex.: Maratona do Recife) e entregar um relat√≥rio executivo que responde a tr√™s perguntas fundamentais:

1. **Quais marcas aparecem mais no evento?**
2. **Quais produtos s√£o mais usados pelos atletas?**
3. **Qual √© o share de mercado visual de cada marca?**

### 1.2. Principais Entreg√°veis

| Entreg√°vel | Descri√ß√£o | Formato |
|------------|-----------|---------|
| **Pipeline de Processamento** | Sistema end-to-end que processa fotos e extrai dados | C√≥digo Python + Infraestrutura |
| **Dataset Anal√≠tico** | Tabelas estruturadas com m√©tricas de presen√ßa de marca | PostgreSQL + CSV/Parquet |
| **Relat√≥rio Executivo** | Documento PDF com insights em linguagem natural | PDF gerado via LLM |
| **Dashboard Interativo** | Visualiza√ß√µes explorat√≥rias dos dados | Metabase (recomendado) |
| **API de Consulta** | Endpoints REST para acessar dados agregados | FastAPI |

### 1.3. Motiva√ß√£o de Neg√≥cio

**Problema:** Marcas esportivas investem milh√µes em patroc√≠nios sem ter dados confi√°veis sobre presen√ßa real de seus produtos em eventos. Pesquisas declarativas s√£o imprecisas e caras.

**Solu√ß√£o MVP:** Automatizar a extra√ß√£o de dados visuais de eventos esportivos, transformando fotos em m√©tricas objetivas de presen√ßa de marca, permitindo:
- Medi√ß√£o precisa de ROI de patroc√≠nios
- Identifica√ß√£o de oportunidades de ativa√ß√£o
- Benchmarking competitivo em tempo real
- Decis√µes baseadas em evid√™ncias visuais

**Valor Proposto:** Reduzir o tempo de an√°lise de semanas para horas, com precis√£o superior a pesquisas tradicionais.

### 1.4. Stakeholders

| Stakeholder | Interesse | Entreg√°vel Principal |
|-------------|-----------|---------------------|
| **Organizadores de Eventos** | Validar atratividade para patrocinadores | Relat√≥rio de presen√ßa de marca |
| **Marcas Patrocinadoras** | Medir ROI e efic√°cia de ativa√ß√µes | Dashboard com m√©tricas de share |
| **Marcas do Setor** | Benchmarking competitivo | Comparativo de presen√ßa visual |
| **Midiaz (Interno)** | Validar proposta de valor B2B | Pipeline funcional e case de sucesso |

### 1.5. Escopo do MVP - Dentro e Fora

#### ‚úÖ **DENTRO DO MVP**

1. **Processamento de 1 evento completo**
   - Ingest√£o de fotos via S3 ou upload direto
   - Processamento batch (n√£o real-time)
   - Suporte a 5-10 marcas principais (Nike, Adidas, Mizuno, Track&Field, etc.)

2. **Extra√ß√£o de dados b√°sicos**
   - Detec√ß√£o de marca (logotipo)
   - Categoria de produto (t√™nis, camiseta, bon√©, √≥culos)
   - Confian√ßa do modelo (score)
   - Metadados do evento (nome, local, data)

3. **M√©tricas calculadas**
   - Share de marca (%)
   - Volume absoluto de apari√ß√µes
   - Ranking de produtos
   - Total de atletas √∫nicos identificados

4. **Entrega anal√≠tica**
   - Relat√≥rio PDF automatizado (100-200 palavras)
   - Dashboard com 4-6 visualiza√ß√µes principais
   - Dataset tabular export√°vel (CSV)

5. **Infraestrutura m√≠nima**
   - Backend FastAPI
   - PostgreSQL para dados estruturados
   - S3 para armazenamento de imagens
   - Processamento via Lambda ou EC2

#### ‚ùå **FORA DO MVP (v2+)**

1. **Multi-evento e hist√≥rico**
   - Compara√ß√£o entre eventos
   - Tend√™ncias temporais
   - An√°lise de recorr√™ncia de atletas

2. **Detec√ß√µes avan√ßadas**
   - Bounding boxes precisos
   - Detec√ß√£o de idade/g√™nero
   - Classifica√ß√£o de n√≠vel de competi√ß√£o
   - Detec√ß√£o de contexto (in√≠cio/fim de prova)

3. **Produtos customizados**
   - API p√∫blica de dados
   - Integra√ß√£o com sistemas de CRM
   - Alertas e notifica√ß√µes autom√°ticas

4. **An√°lise preditiva**
   - Previs√£o de presen√ßa de marca
   - Recomenda√ß√µes de ativa√ß√£o
   - ROI forecasting

5. **Escala enterprise**
   - Processamento real-time
   - Multi-tenant
   - SLA garantido

---

## 2. Arquitetura Completa da Solu√ß√£o

### 2.1. Vis√£o Geral da Arquitetura

```mermaid
graph TB
    subgraph "Ingest√£o"
        A[Fot√≥grafos] -->|Upload Fotos| B[S3 Bucket Raw]
        C[Metadados Evento] -->|JSON| D[API FastAPI]
    end
    
    subgraph "Processamento"
        B -->|Trigger| E[Lambda/EC2 Processor]
        D -->|Event Metadata| E
        E -->|Vision API| F[AWS Rekognition/OpenAI Vision]
        F -->|Detections| G[PostgreSQL]
    end
    
    subgraph "Enriquecimento"
        G -->|Raw Detections| H[Data Enrichment Service]
        H -->|Normalized Data| G
    end
    
    subgraph "Agrega√ß√£o"
        G -->|Structured Data| I[Aggregation Engine]
        I -->|Metrics| J[Analytical Tables]
    end
    
    subgraph "Entrega"
        J -->|Data| K[Metabase Dashboard]
        J -->|Data| L[Report Generator LLM]
        L -->|PDF| M[S3 Reports]
        J -->|API| N[FastAPI REST]
    end
    
    style B fill:#e1f5ff
    style G fill:#fff4e1
    style J fill:#e8f5e9
    style K fill:#f3e5f5
    style M fill:#f3e5f5
```

**Decis√£o Arquitetural:** Optamos por uma arquitetura **h√≠brida serverless + containerizada**:
- **Serverless (Lambda)** para processamento batch de imagens (custo-efetivo)
- **Containerizado (EC2/Fargate)** para servi√ßos de longa dura√ß√£o (agrega√ß√£o, enriquecimento)
- **PostgreSQL** como fonte √∫nica de verdade (relacional para queries complexas)
- **S3** como data lake para imagens brutas e relat√≥rios gerados

### 2.2. Arquitetura de Dados

#### 2.2.1. Fluxo de Dados End-to-End

```mermaid
flowchart LR
    A[Fotos Raw<br/>S3] -->|Ingest| B[Preprocessing<br/>Resize/Normalize]
    B -->|Batch| C[Vision API<br/>Rekognition/Vision]
    C -->|JSON Detections| D[Extraction Service<br/>Parse & Validate]
    D -->|Structured| E[PostgreSQL<br/>Raw Detections]
    E -->|ETL| F[Enrichment<br/>Normalize Brands]
    F -->|Enriched| G[PostgreSQL<br/>Normalized Data]
    G -->|Aggregation| H[Analytical Tables<br/>Brand Metrics]
    H -->|Query| I[Dashboard/Report]
    
    style A fill:#ffebee
    style E fill:#fff3e0
    style G fill:#e8f5e9
    style H fill:#e3f2fd
```

#### 2.2.2. Camadas de Armazenamento

| Camada | Tecnologia | Prop√≥sito | Reten√ß√£o |
|--------|------------|-----------|----------|
| **Raw Images** | S3 (Standard) | Fotos originais do evento | 90 dias |
| **Processed Images** | S3 (Standard-IA) | Imagens pr√©-processadas | 30 dias |
| **Raw Detections** | PostgreSQL | Resultados brutos da API de vis√£o | Permanente |
| **Normalized Data** | PostgreSQL | Dados enriquecidos e validados | Permanente |
| **Analytical Tables** | PostgreSQL | M√©tricas agregadas por evento | Permanente |
| **Reports** | S3 (Standard) | PDFs gerados | 1 ano |

**Decis√£o:** Usar **PostgreSQL** em vez de DynamoDB porque:
- Queries anal√≠ticas complexas (JOINs, GROUP BY, window functions)
- Relacionamentos entre eventos, marcas, produtos
- Facilita cria√ß√£o de views materializadas
- Custo previs√≠vel (RDS t3.medium ~$70/m√™s)

#### 2.2.3. Cat√°logo de Dados

**Metadados do Evento (Event Metadata)**
```json
{
  "event_id": "uuid",
  "event_name": "Maratona do Recife 2025",
  "event_type": "corrida",
  "event_date": "2025-05-12",
  "event_location": "Recife, PE",
  "total_photos": 14532,
  "total_athletes_estimated": 8920,
  "photographer_ids": ["photographer_001", "photographer_002"],
  "status": "processing|completed|failed",
  "created_at": "2025-05-12T06:00:00Z",
  "processed_at": "2025-05-12T14:30:00Z"
}
```

**Metadados de Processamento**
- Vers√£o do modelo de vis√£o usado
- Timestamp de cada etapa
- Erros e retries
- Custo estimado de processamento

### 2.3. Arquitetura de Backend

#### 2.3.1. Servi√ßos Principais

```mermaid
graph TB
    subgraph "API Layer"
        A[FastAPI Gateway] -->|Routes| B[Event Controller]
        A -->|Routes| C[Report Controller]
        A -->|Routes| D[Data Controller]
    end
    
    subgraph "Business Logic"
        B -->|Orchestrates| E[Event Service]
        C -->|Orchestrates| F[Report Service]
        D -->|Orchestrates| G[Data Service]
        
        E -->|Uses| H[Ingestion Service]
        E -->|Uses| I[Processing Service]
        F -->|Uses| J[LLM Service]
        G -->|Uses| K[Aggregation Service]
    end
    
    subgraph "Data Layer"
        H -->|Writes| L[PostgreSQL]
        I -->|Writes| L
        K -->|Reads| L
        J -->|Reads| L
    end
    
    subgraph "External Services"
        I -->|Calls| M[AWS Rekognition]
        J -->|Calls| N[OpenAI API]
        H -->|Reads| O[S3 Bucket]
    end
    
    style A fill:#4fc3f7
    style E fill:#81c784
    style L fill:#ffb74d
    style M fill:#ba68c8
    style N fill:#ba68c8
```

#### 2.3.2. Fila/Event-Driven (Opcional no MVP)

**Recomenda√ß√£o:** **N√ÉO usar fila no MVP**. Processamento s√≠ncrono via Lambda com timeout de 15 minutos √© suficiente.

**Justificativa:**
- MVP processa 1 evento por vez
- Volume baixo (< 20k imagens/evento)
- Complexidade desnecess√°ria para MVP
- Custo adicional (SQS, EventBridge)

**Para v2:** Implementar SQS + Step Functions quando houver multi-evento e processamento paralelo.

#### 2.3.3. Orquestra√ß√£o

**MVP:** Processamento sequencial simples
```
1. Ingest√£o ‚Üí 2. Preprocessing ‚Üí 3. Vision API ‚Üí 4. Enrichment ‚Üí 5. Aggregation ‚Üí 6. Report Generation
```

**v2:** Step Functions para orquestra√ß√£o complexa com retry e error handling.

#### 2.3.4. API para Consulta (MVP)

**Endpoints Essenciais:**

```python
# Eventos
GET    /api/v1/events                    # Lista eventos
GET    /api/v1/events/{event_id}          # Detalhes do evento
POST   /api/v1/events                    # Cria novo evento
GET    /api/v1/events/{event_id}/status   # Status do processamento

# Relat√≥rios
GET    /api/v1/events/{event_id}/report   # Gera/retorna relat√≥rio PDF
GET    /api/v1/events/{event_id}/summary  # Resumo JSON

# Dados Anal√≠ticos
GET    /api/v1/events/{event_id}/brands   # Lista marcas detectadas
GET    /api/v1/events/{event_id}/products # Lista produtos detectados
GET    /api/v1/events/{event_id}/metrics # M√©tricas agregadas
```

**Decis√£o:** FastAPI porque:
- Async nativo (melhor para I/O com APIs externas)
- Valida√ß√£o autom√°tica com Pydantic
- Documenta√ß√£o autom√°tica (Swagger)
- F√°cil integra√ß√£o com servi√ßos Python (pandas, SQLAlchemy)

### 2.4. Arquitetura de IA e Vis√£o Computacional

#### 2.4.1. Modelo de Detec√ß√£o de Marca

**Recomenda√ß√£o MVP: AWS Rekognition Custom Labels**

**Por qu√™?**
- ‚úÖ Treinamento customizado com dataset de marcas esportivas
- ‚úÖ Alta precis√£o para logotipos conhecidos (Nike, Adidas, etc.)
- ‚úÖ Gerenciado pela AWS (sem infraestrutura pr√≥pria)
- ‚úÖ Custo: $1.00 por hora de treinamento + $4.00 por 1.000 imagens infer√™ncia

**Alternativa (se custo for limitante):** OpenAI Vision API
- ‚úÖ Boa detec√ß√£o zero-shot de marcas conhecidas
- ‚úÖ Custo: $0.01-0.03 por imagem
- ‚ùå Menos preciso que modelo customizado
- ‚ùå Pode ter alucina√ß√µes

**Estrat√©gia H√≠brida (Recomendada):**
1. **Fase 1 (MVP):** OpenAI Vision API para valida√ß√£o r√°pida
2. **Fase 2 (v1):** Treinar modelo customizado Rekognition com 500-1000 imagens anotadas
3. **Fase 3 (v2):** Fine-tuning cont√≠nuo com feedback loop

#### 2.4.2. Modelo de Detec√ß√£o de Categoria de Produto

**Recomenda√ß√£o: OpenAI Vision API com Prompt Engineering**

**Prompt Estruturado:**
```
Analise esta imagem de evento esportivo e identifique:
1. Tipo de produto esportivo vis√≠vel (t√™nis, camiseta, bon√©, √≥culos, short, meia)
2. Marca do produto (se identific√°vel)
3. Confian√ßa da detec√ß√£o (alto/m√©dio/baixo)

Retorne JSON:
{
  "products": [
    {
      "type": "t√™nis",
      "brand": "Nike",
      "confidence": "alto"
    }
  ]
}
```

**Por qu√™ n√£o modelo customizado?**
- Categorias s√£o gen√©ricas (t√™nis, camiseta) - n√£o precisa de treinamento
- OpenAI Vision tem boa performance zero-shot
- Custo menor que treinar modelo pr√≥prio

#### 2.4.3. Modelo de Estimativa de Idade/G√™nero (Opcional MVP)

**Status:** ‚ùå **FORA DO MVP**

**Justificativa:**
- Complexidade adicional sem valor imediato
- Quest√µes √©ticas de privacidade
- Baixa precis√£o em imagens esportivas (dist√¢ncia, movimento)

**Para v2:** Implementar com AWS Rekognition Face Analysis (se necess√°rio para segmenta√ß√£o demogr√°fica).

#### 2.4.4. Estrat√©gia de Infer√™ncia

**MVP: Processamento Batch Ass√≠ncrono**

```mermaid
sequenceDiagram
    participant U as User/API
    participant L as Lambda Processor
    participant R as Rekognition/Vision API
    participant DB as PostgreSQL
    participant S3 as S3 Bucket
    
    U->>L: Trigger processamento evento
    L->>S3: Lista imagens do evento
    loop Para cada imagem
        L->>R: Detect brands & products
        R-->>L: JSON detections
        L->>DB: Salva raw detection
    end
    L->>DB: Agrega m√©tricas
    L->>U: Status: completed
```

**Configura√ß√£o Lambda:**
- **Timeout:** 15 minutos (m√°ximo AWS)
- **Memory:** 3GB (para processar m√∫ltiplas imagens em paralelo)
- **Concurrency:** 1 (evitar rate limits da API)
- **Retry:** 3 tentativas com backoff exponencial

**Otimiza√ß√£o de Custo:**
- Processar imagens em batches de 10
- Cache de resultados (evitar reprocessar mesma imagem)
- Compress√£o de imagens antes do envio (reduz custo de API)

#### 2.4.5. Pipeline de Pr√©-processamento

**Etapas:**

1. **Valida√ß√£o de Imagem**
   - Formato suportado (JPEG, PNG)
   - Tamanho m√≠nimo (100x100px)
   - Tamanho m√°ximo (10MB)

2. **Normaliza√ß√£o**
   - Redimensionar para 1024x1024px (mant√©m aspect ratio)
   - Compress√£o JPEG qualidade 85%
   - Convers√£o para RGB (remove alpha channel)

3. **Otimiza√ß√£o para API**
   - Base64 encoding (se necess√°rio)
   - Batch de 10 imagens por requisi√ß√£o

**C√≥digo Exemplo:**
```python
from PIL import Image
import io

def preprocess_image(image_bytes: bytes) -> bytes:
    img = Image.open(io.BytesIO(image_bytes))
    img = img.convert('RGB')
    img.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
    
    output = io.BytesIO()
    img.save(output, format='JPEG', quality=85, optimize=True)
    return output.getvalue()
```

#### 2.4.6. Armazenamento de Resultados

**Estrutura no PostgreSQL:**

```sql
-- Tabela de detec√ß√µes brutas
CREATE TABLE raw_detections (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_id UUID NOT NULL REFERENCES events(id),
    photo_s3_key VARCHAR(500) NOT NULL,
    detection_type VARCHAR(50) NOT NULL, -- 'brand' ou 'product'
    detected_label VARCHAR(200),
    confidence_score DECIMAL(5,4),
    bounding_box JSONB, -- {x, y, width, height} - NULL no MVP
    raw_response JSONB, -- Resposta completa da API
    created_at TIMESTAMP DEFAULT NOW()
);

-- √çndices para performance
CREATE INDEX idx_raw_detections_event ON raw_detections(event_id);
CREATE INDEX idx_raw_detections_type ON raw_detections(detection_type);
CREATE INDEX idx_raw_detections_label ON raw_detections(detected_label);
```

### 2.5. Arquitetura do Produto Anal√≠tico

#### 2.5.1. Decis√£o: Dashboard + Relat√≥rio PDF

**Recomenda√ß√£o:** **Ambos no MVP**

**Justificativa:**
- **Dashboard (Metabase):** Explora√ß√£o interativa, drill-down, filtros
- **Relat√≥rio PDF:** Documento executivo para apresenta√ß√µes, email, impress√£o

**Custo:** Metabase Open Source (self-hosted) = $0 | Metabase Cloud = $85/m√™s

#### 2.5.2. Dashboard - Metabase (Recomendado)

**Por qu√™ Metabase?**
- ‚úÖ Open source (sem custo no MVP)
- ‚úÖ F√°cil conex√£o com PostgreSQL
- ‚úÖ Interface intuitiva (n√£o precisa de SQL avan√ßado)
- ‚úÖ Embedding poss√≠vel (para v2)
- ‚úÖ Suporte a exporta√ß√£o (CSV, PDF, XLSX)

**Alternativas Consideradas:**
- **Superset:** Mais complexo, curva de aprendizado maior
- **Power BI Embedded:** Custo alto ($10/usu√°rio/m√™s)
- **Looker Studio:** Gratuito mas limitado, depend√™ncia Google

**Visualiza√ß√µes Principais (MVP):**

1. **Share de Marca (Pizza Chart)**
   - % de cada marca no evento
   - Filtro por categoria de produto

2. **Ranking de Marcas (Bar Chart)**
   - Volume absoluto de apari√ß√µes
   - Ordenado por share

3. **Distribui√ß√£o de Produtos (Treemap)**
   - T√™nis vs Camiseta vs Acess√≥rios
   - Cores por marca

4. **Timeline de Detec√ß√µes (Line Chart)**
   - Apari√ß√µes ao longo do evento (se timestamp dispon√≠vel)

5. **Tabela Detalhada (Data Table)**
   - Marca | Produto | Apari√ß√µes | Share | Confian√ßa M√©dia

**Fonte de Dados:** Views materializadas no PostgreSQL

```sql
CREATE MATERIALIZED VIEW brand_event_summary AS
SELECT 
    e.id as event_id,
    e.event_name,
    b.normalized_brand,
    COUNT(DISTINCT rd.id) as total_detections,
    COUNT(DISTINCT rd.photo_s3_key) as photos_with_brand,
    AVG(rd.confidence_score) as avg_confidence,
    ROUND(
        100.0 * COUNT(DISTINCT rd.id) / 
        (SELECT COUNT(*) FROM raw_detections WHERE event_id = e.id),
        2
    ) as brand_share_percent
FROM events e
JOIN raw_detections rd ON rd.event_id = e.id
JOIN brand_normalization b ON b.detected_label = rd.detected_label
WHERE rd.detection_type = 'brand'
GROUP BY e.id, e.event_name, b.normalized_brand;
```

#### 2.5.3. Relat√≥rio PDF Automatizado

**Stack:**
- **LLM:** OpenAI GPT-4 (ou GPT-3.5-turbo para custo)
- **Template Engine:** Jinja2
- **PDF Generator:** ReportLab ou WeasyPrint
- **Storage:** S3 (acesso via URL assinada)

**Fluxo:**

```mermaid
graph LR
    A[Agrega√ß√£o Completa] -->|Dados JSON| B[LLM Service]
    B -->|Prompt + Context| C[OpenAI API]
    C -->|Texto Narrativo| D[Template Engine]
    D -->|HTML/Markdown| E[PDF Generator]
    E -->|PDF| F[S3 Bucket]
    F -->|URL| G[API Response]
```

**Template do Prompt (do documento de Idea√ß√£o):**

```python
PROMPT_TEMPLATE = """
Voc√™ √© um analista de marketing esportivo da plataforma Midiaz.

Com base nas seguintes informa√ß√µes visuais, gere um relat√≥rio executivo sobre a presen√ßa de marca.

Dados:
- Evento: {event_name}
- Local: {event_location}
- Data: {event_date}
- Total de atletas identificados: {total_athletes}
- Total de imagens analisadas: {total_images}
- Marcas detectadas e frequ√™ncia:
{brands_list}

Instru√ß√µes:
1. Resuma os principais destaques sobre a presen√ßa de marca.
2. Destaque a marca mais recorrente e o tipo de produto mais identificado.
3. Contextualize brevemente o tipo de evento esportivo.
4. A sa√≠da deve estar em linguagem natural, formal e voltada para gestores de marketing esportivo.
5. Finalize o relat√≥rio com um insight estrat√©gico curto (1 frase) sobre como a marca pode otimizar seu desempenho futuro.
"""
```

**Estrutura do PDF:**
1. Capa (logo Midiaz, nome do evento, data)
2. Resumo Executivo (2-3 par√°grafos do LLM)
3. M√©tricas Principais (tabela com top 5 marcas)
4. Visualiza√ß√µes (gr√°ficos exportados do Metabase)
5. Detalhamento por Categoria (t√™nis, camiseta, etc.)
6. Insight Estrat√©gico (destaque do LLM)

**Custo Estimado:** $0.03-0.06 por relat√≥rio (GPT-3.5-turbo)

---

## 3. Design do Software

### 3.1. M√≥dulos do Sistema

```
midiaz-b2b/
‚îú‚îÄ‚îÄ ingestion/              # M√≥dulo de ingest√£o
‚îÇ   ‚îú‚îÄ‚îÄ s3_loader.py        # Carrega imagens do S3
‚îÇ   ‚îú‚îÄ‚îÄ metadata_parser.py  # Parse metadados do evento
‚îÇ   ‚îî‚îÄ‚îÄ validator.py        # Valida√ß√£o de entrada
‚îÇ
‚îú‚îÄ‚îÄ preprocessing/          # Pr√©-processamento de imagens
‚îÇ   ‚îú‚îÄ‚îÄ image_normalizer.py # Redimensiona, comprime
‚îÇ   ‚îú‚îÄ‚îÄ batch_processor.py  # Agrupa imagens em batches
‚îÇ   ‚îî‚îÄ‚îÄ quality_checker.py  # Valida qualidade da imagem
‚îÇ
‚îú‚îÄ‚îÄ vision_extraction/      # Integra√ß√£o com APIs de vis√£o
‚îÇ   ‚îú‚îÄ‚îÄ rekognition_client.py  # Cliente AWS Rekognition
‚îÇ   ‚îú‚îÄ‚îÄ openai_vision_client.py # Cliente OpenAI Vision
‚îÇ   ‚îú‚îÄ‚îÄ detection_parser.py    # Parse respostas da API
‚îÇ   ‚îî‚îÄ‚îÄ confidence_filter.py   # Filtra por confian√ßa m√≠nima
‚îÇ
‚îú‚îÄ‚îÄ data_enrichment/       # Enriquecimento de dados
‚îÇ   ‚îú‚îÄ‚îÄ brand_normalizer.py    # Normaliza nomes de marcas
‚îÇ   ‚îú‚îÄ‚îÄ product_classifier.py  # Classifica produtos
‚îÇ   ‚îî‚îÄ‚îÄ metadata_enricher.py   # Adiciona contexto
‚îÇ
‚îú‚îÄ‚îÄ dataset_writer/         # Escrita no banco
‚îÇ   ‚îú‚îÄ‚îÄ db_writer.py       # Insere no PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ schema_validator.py # Valida schemas
‚îÇ   ‚îî‚îÄ‚îÄ batch_inserter.py  # Inser√ß√£o em lote otimizada
‚îÇ
‚îú‚îÄ‚îÄ aggregation/           # Agrega√ß√£o de m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ brand_aggregator.py   # Agrega por marca
‚îÇ   ‚îú‚îÄ‚îÄ product_aggregator.py # Agrega por produto
‚îÇ   ‚îî‚îÄ‚îÄ metrics_calculator.py # Calcula shares, rankings
‚îÇ
‚îú‚îÄ‚îÄ report_generator/      # Gera√ß√£o de relat√≥rios
‚îÇ   ‚îú‚îÄ‚îÄ llm_service.py     # Integra√ß√£o com OpenAI
‚îÇ   ‚îú‚îÄ‚îÄ prompt_builder.py  # Constr√≥i prompts
‚îÇ   ‚îú‚îÄ‚îÄ pdf_generator.py   # Gera PDF
‚îÇ   ‚îî‚îÄ‚îÄ template_engine.py # Template Jinja2
‚îÇ
‚îú‚îÄ‚îÄ api/                   # API FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ events.py      # Rotas de eventos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reports.py     # Rotas de relat√≥rios
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data.py        # Rotas de dados
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Pydantic models
‚îÇ   ‚îî‚îÄ‚îÄ dependencies.py    # Inje√ß√£o de depend√™ncias
‚îÇ
‚îî‚îÄ‚îÄ infrastructure/        # Infraestrutura
    ‚îú‚îÄ‚îÄ database.py        # Conex√£o PostgreSQL
    ‚îú‚îÄ‚îÄ s3_client.py       # Cliente S3
    ‚îî‚îÄ‚îÄ config.py          # Configura√ß√µes
```

### 3.2. Estrutura de Pastas do Projeto

```
midiaz-top4/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ BUILD.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ CONTEXT.md
‚îÇ   ‚îú‚îÄ‚îÄ event_brand_report_technical_plan.md
‚îÇ   ‚îú‚îÄ‚îÄ etapas/
‚îÇ   ‚îî‚îÄ‚îÄ arquitetura/
‚îÇ       ‚îú‚îÄ‚îÄ c4_context.md
‚îÇ       ‚îú‚îÄ‚îÄ c4_container.md
‚îÇ       ‚îî‚îÄ‚îÄ c4_component.md
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/
‚îÇ   ‚îú‚îÄ‚îÄ vision_extraction/
‚îÇ   ‚îú‚îÄ‚îÄ data_enrichment/
‚îÇ   ‚îú‚îÄ‚îÄ dataset_writer/
‚îÇ   ‚îú‚îÄ‚îÄ aggregation/
‚îÇ   ‚îú‚îÄ‚îÄ report_generator/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ e2e/
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup_db.sql
‚îÇ   ‚îú‚îÄ‚îÄ seed_brands.py
‚îÇ   ‚îî‚îÄ‚îÄ process_event.py
‚îÇ
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ terraform/         # IaC (opcional no MVP)
‚îÇ   ‚îî‚îÄ‚îÄ cloudformation/    # CloudFormation templates
‚îÇ
‚îî‚îÄ‚îÄ .github/
    ‚îî‚îÄ‚îÄ workflows/
        ‚îî‚îÄ‚îÄ ci.yml
```

**Explica√ß√£o de Diret√≥rios:**

- **`docs/`**: Documenta√ß√£o t√©cnica e metodol√≥gica
- **`src/`**: C√≥digo-fonte organizado por m√≥dulos
- **`tests/`**: Testes unit√°rios, integra√ß√£o e end-to-end
- **`scripts/`**: Scripts utilit√°rios (setup, seed, processamento manual)
- **`infrastructure/`**: C√≥digo de infraestrutura como c√≥digo (IaC)

### 3.3. Padr√µes de Design Recomendados

#### 3.3.1. Arquitetura Hexagonal (Ports & Adapters)

**Aplica√ß√£o no MVP:**

```python
# Port (Interface)
class VisionServicePort(ABC):
    @abstractmethod
    def detect_brands(self, image_bytes: bytes) -> List[BrandDetection]:
        pass

# Adapter (Implementa√ß√£o)
class RekognitionAdapter(VisionServicePort):
    def detect_brands(self, image_bytes: bytes) -> List[BrandDetection]:
        # Implementa√ß√£o espec√≠fica AWS Rekognition
        pass

class OpenAIVisionAdapter(VisionServicePort):
    def detect_brands(self, image_bytes: bytes) -> List[BrandDetection]:
        # Implementa√ß√£o espec√≠fica OpenAI
        pass

# Use Case (Core Business Logic)
class ProcessImageUseCase:
    def __init__(self, vision_service: VisionServicePort):
        self.vision_service = vision_service
    
    def execute(self, image: Image) -> ProcessedImage:
        detections = self.vision_service.detect_brands(image.bytes)
        return ProcessedImage(image, detections)
```

**Benef√≠cios:**
- Troca de provedor de vis√£o sem alterar l√≥gica de neg√≥cio
- Testes unit√°rios com mocks f√°ceis
- Desacoplamento de depend√™ncias externas

#### 3.3.2. Princ√≠pios SOLID Aplicados

**S - Single Responsibility:**
- Cada m√≥dulo tem uma responsabilidade √∫nica
- Ex: `brand_normalizer.py` s√≥ normaliza marcas, n√£o faz queries no banco

**O - Open/Closed:**
- Extens√≠vel via interfaces (Ports)
- Ex: Adicionar novo provedor de vis√£o sem modificar c√≥digo existente

**L - Liskov Substitution:**
- Adapters s√£o substitu√≠veis
- Ex: `RekognitionAdapter` e `OpenAIVisionAdapter` s√£o intercambi√°veis

**I - Interface Segregation:**
- Interfaces espec√≠ficas (n√£o uma interface gigante)
- Ex: `VisionServicePort` separado de `ReportServicePort`

**D - Dependency Inversion:**
- Depender de abstra√ß√µes, n√£o implementa√ß√µes
- Ex: `ProcessImageUseCase` depende de `VisionServicePort`, n√£o de `RekognitionAdapter`

#### 3.3.3. DTOs, Schemas e Valida√ß√µes

**Pydantic Models (DTOs):**

```python
from pydantic import BaseModel, Field, validator
from typing import List, Optional
from decimal import Decimal

class BrandDetection(BaseModel):
    brand: str = Field(..., min_length=1, max_length=200)
    confidence: Decimal = Field(..., ge=0, le=1)
    bounding_box: Optional[dict] = None
    
    @validator('brand')
    def normalize_brand(cls, v):
        return v.strip().title()

class ProductDetection(BaseModel):
    product_type: str = Field(..., regex='^(t√™nis|camiseta|bon√©|√≥culos|short|meia)$')
    brand: Optional[str] = None
    confidence: Decimal = Field(..., ge=0, le=1)

class EventMetadata(BaseModel):
    event_name: str = Field(..., min_length=3, max_length=200)
    event_date: date
    event_location: str
    event_type: str = Field(..., regex='^(corrida|triatlo|beach tennis|ciclismo)$')
    
    class Config:
        json_schema_extra = {
            "example": {
                "event_name": "Maratona do Recife 2025",
                "event_date": "2025-05-12",
                "event_location": "Recife, PE",
                "event_type": "corrida"
            }
        }
```

**Valida√ß√£o de Schemas no Banco:**

```python
# Usar SQLAlchemy com valida√ß√£o
from sqlalchemy import Column, String, DECIMAL, JSON
from sqlalchemy.dialects.postgresql import UUID
import uuid

class RawDetection(Base):
    __tablename__ = 'raw_detections'
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    detected_label = Column(String(200), nullable=False)
    confidence_score = Column(DECIMAL(5, 4), nullable=False)
    
    @validates('confidence_score')
    def validate_confidence(self, key, value):
        if not (0 <= value <= 1):
            raise ValueError("Confidence must be between 0 and 1")
        return value
```

#### 3.3.4. Padr√µes para M√≥dulos de IA

**1. Strategy Pattern para M√∫ltiplos Modelos:**

```python
class VisionModelStrategy(ABC):
    @abstractmethod
    def detect(self, image: bytes) -> DetectionResult:
        pass

class RekognitionStrategy(VisionModelStrategy):
    def detect(self, image: bytes) -> DetectionResult:
        # L√≥gica espec√≠fica Rekognition
        pass

class VisionModelFactory:
    @staticmethod
    def create(model_type: str) -> VisionModelStrategy:
        if model_type == "rekognition":
            return RekognitionStrategy()
        elif model_type == "openai":
            return OpenAIVisionStrategy()
        else:
            raise ValueError(f"Unknown model: {model_type}")
```

**2. Retry Pattern para APIs Externas:**

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def call_vision_api(image: bytes) -> DetectionResult:
    # Chamada √† API com retry autom√°tico
    pass
```

**3. Circuit Breaker para Preven√ß√£o de Cascata:**

```python
from circuitbreaker import circuit

@circuit(failure_threshold=5, recovery_timeout=60)
def call_external_api(image: bytes):
    # Se 5 falhas consecutivas, para de tentar por 60s
    pass
```

### 3.4. Fluxos Ass√≠ncronos vs S√≠ncronos

#### 3.4.1. Processamento S√≠ncrono (MVP)

**Quando usar:**
- Upload de metadados do evento
- Consulta de relat√≥rio j√° gerado
- API de m√©tricas (dados j√° agregados)

**Exemplo:**
```python
@app.post("/api/v1/events")
async def create_event(event: EventMetadata):
    # Cria evento no banco (s√≠ncrono, r√°pido)
    event_id = event_service.create(event)
    return {"event_id": event_id, "status": "created"}
```

#### 3.4.2. Processamento Ass√≠ncrono (MVP)

**Quando usar:**
- Processamento de imagens (pode levar minutos/horas)
- Gera√ß√£o de relat√≥rio PDF (chamada LLM + gera√ß√£o PDF)

**Estrat√©gia MVP:**
```python
@app.post("/api/v1/events/{event_id}/process")
async def trigger_processing(event_id: str):
    # Dispara processamento ass√≠ncrono
    # Retorna imediatamente com status "processing"
    process_event_async.delay(event_id)  # Celery ou Lambda
    return {"status": "processing", "event_id": event_id}

@app.get("/api/v1/events/{event_id}/status")
async def get_processing_status(event_id: str):
    # Consulta status do processamento
    status = event_service.get_status(event_id)
    return {"status": status}  # "processing" | "completed" | "failed"
```

**Implementa√ß√£o com Lambda:**
- API recebe requisi√ß√£o
- Dispara Lambda ass√≠ncrona via EventBridge
- Lambda processa em background
- Status atualizado no banco
- Cliente consulta status via polling

#### 3.4.3. Processamento Batch

**Quando usar:**
- Processamento de m√∫ltiplas imagens
- Agrega√ß√£o de m√©tricas
- Gera√ß√£o de relat√≥rios em lote

**Exemplo:**
```python
def process_event_batch(event_id: str):
    images = s3_service.list_images(event_id)
    
    # Processa em batches de 10
    for batch in chunks(images, 10):
        detections = vision_service.detect_batch(batch)
        db_writer.save_batch(detections)
    
    # Ap√≥s todas as imagens processadas
    aggregation_service.aggregate(event_id)
    report_service.generate(event_id)
```

---

## 4. Especifica√ß√£o Detalhada dos Dados

### 4.1. Campos Extra√≠dos das Imagens

#### 4.1.1. Detec√ß√£o de Marca

| Campo | Tipo | Descri√ß√£o | Exemplo | Obrigat√≥rio MVP |
|-------|------|-----------|---------|-----------------|
| `brand` | String(200) | Nome da marca detectada | "Nike" | ‚úÖ |
| `confidence` | Decimal(5,4) | Confian√ßa do modelo (0-1) | 0.9234 | ‚úÖ |
| `bounding_box` | JSONB | Coordenadas {x, y, width, height} | `{"x": 100, "y": 200, "width": 50, "height": 30}` | ‚ùå (v2) |
| `detection_type` | String(50) | Tipo: "brand" ou "product" | "brand" | ‚úÖ |
| `photo_s3_key` | String(500) | Chave S3 da imagem | "events/recife-2025/photo_001.jpg" | ‚úÖ |
| `timestamp` | Timestamp | Quando a detec√ß√£o foi feita | 2025-05-12T14:30:00Z | ‚úÖ |

#### 4.1.2. Detec√ß√£o de Produto

| Campo | Tipo | Descri√ß√£o | Exemplo | Obrigat√≥rio MVP |
|-------|------|-----------|---------|-----------------|
| `product_type` | String(50) | Categoria do produto | "t√™nis" | ‚úÖ |
| `brand` | String(200) | Marca associada (se detectada) | "Adidas" | ‚ö†Ô∏è (opcional) |
| `confidence` | Decimal(5,4) | Confian√ßa do modelo | 0.8567 | ‚úÖ |
| `subcategory` | String(100) | Subcategoria (ex: "t√™nis corrida") | "t√™nis corrida" | ‚ùå (v2) |

#### 4.1.3. Metadados do Atleta (Anonimizado)

| Campo | Tipo | Descri√ß√£o | Exemplo | Obrigat√≥rio MVP |
|-------|------|-----------|---------|-----------------|
| `athlete_id` | UUID | ID √∫nico anonimizado | uuid | ‚úÖ |
| `photo_count` | Integer | Quantas fotos o atleta aparece | 5 | ‚úÖ |
| `first_seen` | Timestamp | Primeira apari√ß√£o no evento | 2025-05-12T06:00:00Z | ‚úÖ |
| `last_seen` | Timestamp | √öltima apari√ß√£o | 2025-05-12T10:30:00Z | ‚úÖ |

**Nota:** No MVP, n√£o identificamos atletas espec√≠ficos. `athlete_id` √© gerado por hash da face (se dispon√≠vel) ou posi√ß√£o na foto.

#### 4.1.4. Metadados do Fot√≥grafo

| Campo | Tipo | Descri√ß√£o | Exemplo | Obrigat√≥rio MVP |
|-------|------|-----------|---------|-----------------|
| `photographer_id` | String(100) | ID do fot√≥grafo | "photographer_001" | ‚úÖ |
| `photos_uploaded` | Integer | Total de fotos enviadas | 14532 | ‚úÖ |
| `upload_timestamp` | Timestamp | Quando as fotos foram enviadas | 2025-05-12T05:00:00Z | ‚úÖ |

#### 4.1.5. Posi√ß√£o no Evento (Opcional)

| Campo | Tipo | Descri√ß√£o | Exemplo | Obrigat√≥rio MVP |
|-------|------|-----------|---------|-----------------|
| `event_position` | String(50) | Localiza√ß√£o no evento | "in√≠cio" | ‚ùå (v2) |
| `kilometer_marker` | Integer | Marca de quil√¥metro (se corrida) | 5 | ‚ùå (v2) |
| `time_of_day` | Time | Hor√°rio da foto | 06:30:00 | ‚ö†Ô∏è (se dispon√≠vel) |

### 4.2. Modelo Tabular Final

#### 4.2.1. Tabela: `events`

Armazena metadados dos eventos esportivos.

```sql
CREATE TABLE events (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_name VARCHAR(200) NOT NULL,
    event_type VARCHAR(50) NOT NULL CHECK (event_type IN ('corrida', 'triatlo', 'beach tennis', 'ciclismo')),
    event_date DATE NOT NULL,
    event_location VARCHAR(200) NOT NULL,
    total_photos INTEGER DEFAULT 0,
    total_athletes_estimated INTEGER,
    status VARCHAR(50) DEFAULT 'created' CHECK (status IN ('created', 'processing', 'completed', 'failed')),
    created_at TIMESTAMP DEFAULT NOW(),
    processed_at TIMESTAMP,
    metadata JSONB, -- Metadados adicionais flex√≠veis
    UNIQUE(event_name, event_date)
);

CREATE INDEX idx_events_date ON events(event_date);
CREATE INDEX idx_events_status ON events(status);
```

**Campos:**
- `id`: Identificador √∫nico do evento
- `event_name`: Nome do evento (ex: "Maratona do Recife 2025")
- `event_type`: Tipo de esporte
- `event_date`: Data do evento
- `event_location`: Localiza√ß√£o (cidade, estado)
- `total_photos`: Total de fotos processadas
- `total_athletes_estimated`: Estimativa de atletas √∫nicos
- `status`: Status do processamento
- `metadata`: JSON flex√≠vel para dados adicionais

#### 4.2.2. Tabela: `photos_raw`

Registro de todas as fotos processadas.

```sql
CREATE TABLE photos_raw (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_id UUID NOT NULL REFERENCES events(id) ON DELETE CASCADE,
    s3_key VARCHAR(500) NOT NULL,
    s3_bucket VARCHAR(200) NOT NULL,
    file_size_bytes BIGINT,
    image_width INTEGER,
    image_height INTEGER,
    photographer_id VARCHAR(100),
    uploaded_at TIMESTAMP,
    processed_at TIMESTAMP DEFAULT NOW(),
    processing_status VARCHAR(50) DEFAULT 'pending',
    UNIQUE(event_id, s3_key)
);

CREATE INDEX idx_photos_event ON photos_raw(event_id);
CREATE INDEX idx_photos_status ON photos_raw(processing_status);
```

#### 4.2.3. Tabela: `raw_detections`

Detec√ß√µes brutas da API de vis√£o computacional.

```sql
CREATE TABLE raw_detections (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_id UUID NOT NULL REFERENCES events(id) ON DELETE CASCADE,
    photo_id UUID NOT NULL REFERENCES photos_raw(id) ON DELETE CASCADE,
    photo_s3_key VARCHAR(500) NOT NULL,
    detection_type VARCHAR(50) NOT NULL CHECK (detection_type IN ('brand', 'product')),
    detected_label VARCHAR(200) NOT NULL, -- Nome bruto da API
    confidence_score DECIMAL(5,4) NOT NULL CHECK (confidence_score >= 0 AND confidence_score <= 1),
    bounding_box JSONB, -- {x, y, width, height} - NULL no MVP
    raw_response JSONB, -- Resposta completa da API para debug
    model_version VARCHAR(50), -- Vers√£o do modelo usado
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_detections_event ON raw_detections(event_id);
CREATE INDEX idx_detections_photo ON raw_detections(photo_id);
CREATE INDEX idx_detections_type ON raw_detections(detection_type);
CREATE INDEX idx_detections_label ON raw_detections(detected_label);
CREATE INDEX idx_detections_confidence ON raw_detections(confidence_score);
```

#### 4.2.4. Tabela: `brand_normalization`

Mapeamento de labels brutos para marcas normalizadas.

```sql
CREATE TABLE brand_normalization (
    id SERIAL PRIMARY KEY,
    detected_label VARCHAR(200) NOT NULL UNIQUE, -- Label da API
    normalized_brand VARCHAR(200) NOT NULL, -- Marca padronizada
    confidence_threshold DECIMAL(5,4) DEFAULT 0.6, -- Limiar m√≠nimo
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Exemplos de mapeamento:
-- "nike" -> "Nike"
-- "Nike Inc." -> "Nike"
-- "adidas" -> "Adidas"
-- "ADIDAS" -> "Adidas"

CREATE INDEX idx_brand_norm_label ON brand_normalization(detected_label);
CREATE INDEX idx_brand_norm_brand ON brand_normalization(normalized_brand);
```

#### 4.2.5. Tabela: `extracted_items`

Items extra√≠dos e normalizados (marcas e produtos).

```sql
CREATE TABLE extracted_items (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_id UUID NOT NULL REFERENCES events(id) ON DELETE CASCADE,
    photo_id UUID NOT NULL REFERENCES photos_raw(id) ON DELETE CASCADE,
    item_type VARCHAR(50) NOT NULL CHECK (item_type IN ('brand', 'product')),
    brand VARCHAR(200), -- NULL se for apenas produto sem marca
    product_type VARCHAR(50), -- NULL se for apenas marca
    normalized_brand VARCHAR(200), -- Marca normalizada (via brand_normalization)
    confidence_score DECIMAL(5,4) NOT NULL,
    source_detection_id UUID REFERENCES raw_detections(id),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_items_event ON extracted_items(event_id);
CREATE INDEX idx_items_brand ON extracted_items(normalized_brand);
CREATE INDEX idx_items_product ON extracted_items(product_type);
CREATE INDEX idx_items_type ON extracted_items(item_type);
```

#### 4.2.6. Tabela: `brand_event_summary`

M√©tricas agregadas por marca e evento (view materializada).

```sql
CREATE MATERIALIZED VIEW brand_event_summary AS
SELECT 
    e.id as event_id,
    e.event_name,
    e.event_date,
    ei.normalized_brand,
    COUNT(DISTINCT ei.photo_id) as photos_with_brand,
    COUNT(DISTINCT ei.id) as total_detections,
    AVG(ei.confidence_score) as avg_confidence,
    MIN(ei.confidence_score) as min_confidence,
    MAX(ei.confidence_score) as max_confidence,
    ROUND(
        100.0 * COUNT(DISTINCT ei.id) / 
        NULLIF((SELECT COUNT(*) FROM extracted_items WHERE event_id = e.id AND item_type = 'brand'), 0),
        2
    ) as brand_share_percent,
    ROUND(
        100.0 * COUNT(DISTINCT ei.photo_id) / 
        NULLIF((SELECT COUNT(DISTINCT photo_id) FROM photos_raw WHERE event_id = e.id), 0),
        2
    ) as photo_coverage_percent
FROM events e
JOIN extracted_items ei ON ei.event_id = e.id
WHERE ei.item_type = 'brand' AND ei.normalized_brand IS NOT NULL
GROUP BY e.id, e.event_name, e.event_date, ei.normalized_brand;

CREATE UNIQUE INDEX idx_brand_summary_unique ON brand_event_summary(event_id, normalized_brand);
CREATE INDEX idx_brand_summary_event ON brand_event_summary(event_id);
CREATE INDEX idx_brand_summary_brand ON brand_event_summary(normalized_brand);
```

**Refresh da View:**
```sql
-- Atualizar ap√≥s processamento completo
REFRESH MATERIALIZED VIEW CONCURRENTLY brand_event_summary;
```

#### 4.2.7. Tabela: `product_event_summary`

M√©tricas agregadas por produto e evento.

```sql
CREATE MATERIALIZED VIEW product_event_summary AS
SELECT 
    e.id as event_id,
    e.event_name,
    ei.product_type,
    COUNT(DISTINCT ei.photo_id) as photos_with_product,
    COUNT(DISTINCT ei.id) as total_detections,
    AVG(ei.confidence_score) as avg_confidence,
    ROUND(
        100.0 * COUNT(DISTINCT ei.id) / 
        NULLIF((SELECT COUNT(*) FROM extracted_items WHERE event_id = e.id AND item_type = 'product'), 0),
        2
    ) as product_share_percent
FROM events e
JOIN extracted_items ei ON ei.event_id = e.id
WHERE ei.item_type = 'product' AND ei.product_type IS NOT NULL
GROUP BY e.id, e.event_name, ei.product_type;

CREATE UNIQUE INDEX idx_product_summary_unique ON product_event_summary(event_id, product_type);
```

#### 4.2.8. Tabela: `report_metadata`

Metadados dos relat√≥rios gerados.

```sql
CREATE TABLE report_metadata (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_id UUID NOT NULL REFERENCES events(id) ON DELETE CASCADE,
    report_type VARCHAR(50) NOT NULL CHECK (report_type IN ('pdf', 'dashboard', 'api')),
    s3_key VARCHAR(500), -- Chave S3 do PDF (se aplic√°vel)
    s3_url VARCHAR(1000), -- URL assinada (tempor√°ria)
    generated_at TIMESTAMP DEFAULT NOW(),
    llm_model_version VARCHAR(50), -- Vers√£o do LLM usado
    llm_prompt_version VARCHAR(50), -- Vers√£o do prompt
    metadata JSONB -- Dados adicionais do relat√≥rio
);

CREATE INDEX idx_reports_event ON report_metadata(event_id);
CREATE INDEX idx_reports_type ON report_metadata(report_type);
```

### 4.3. M√©tricas Calculadas

#### 4.3.1. Share de Marca (Brand Share)

**F√≥rmula:**
```
Brand Share (%) = (Detec√ß√µes da Marca / Total de Detec√ß√µes) √ó 100
```

**Exemplo:**
- Total de detec√ß√µes: 10.000
- Detec√ß√µes Nike: 3.200
- **Nike Share: 32%**

**Implementa√ß√£o SQL:**
```sql
SELECT 
    normalized_brand,
    COUNT(*) as detections,
    ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 2) as share_percent
FROM extracted_items
WHERE event_id = '...' AND item_type = 'brand'
GROUP BY normalized_brand
ORDER BY share_percent DESC;
```

#### 4.3.2. Volume Absoluto

**Defini√ß√£o:** N√∫mero total de apari√ß√µes de uma marca no evento.

**M√©tricas:**
- Total de detec√ß√µes
- Total de fotos com a marca
- Total de atletas √∫nicos (estimado)

#### 4.3.3. Predomin√¢ncia por Categoria

**Defini√ß√£o:** Qual categoria de produto tem maior presen√ßa.

**Exemplo:**
- T√™nis: 64% das detec√ß√µes
- Camisetas: 28%
- Acess√≥rios: 8%

#### 4.3.4. Ranking de Produtos

**Ordena√ß√£o:** Por volume absoluto ou share.

**Exemplo:**
1. T√™nis Nike (2.500 detec√ß√µes, 25%)
2. T√™nis Adidas (2.000 detec√ß√µes, 20%)
3. Camiseta Nike (1.800 detec√ß√µes, 18%)

#### 4.3.5. Distribui√ß√£o por Faixa Et√°ria (v2)

**Status:** ‚ùå Fora do MVP

**Para v2:** Usar AWS Rekognition Face Analysis para estimar idade.

#### 4.3.6. Comparativo entre Marcas

**M√©tricas:**
- Share relativo (%)
- Volume absoluto
- Confian√ßa m√©dia
- Cobertura de fotos (em quantas fotos aparece)

**Visualiza√ß√£o:** Tabela comparativa com ranking.

---

## 5. Pipeline de Processamento

### 5.1. Passo a Passo Detalhado

#### 5.1.1. Ingest√£o

**Objetivo:** Carregar fotos e metadados do evento no sistema.

**Input:**
- Fotos no S3 (bucket: `midiaz-raw-images`)
- Metadados do evento (JSON via API ou arquivo)

**Processo:**
1. Valida√ß√£o de formato (JPEG, PNG)
2. Valida√ß√£o de tamanho (m√≠n: 100x100px, m√°x: 10MB)
3. Registro no banco (`photos_raw`)
4. Trigger de processamento

**C√≥digo Exemplo:**
```python
async def ingest_event(event_metadata: EventMetadata, s3_prefix: str):
    # 1. Criar evento no banco
    event = await event_service.create(event_metadata)
    
    # 2. Listar imagens no S3
    images = await s3_service.list_images(s3_prefix)
    
    # 3. Validar e registrar cada imagem
    for image_key in images:
        metadata = await s3_service.get_metadata(image_key)
        photo = await photo_service.create({
            "event_id": event.id,
            "s3_key": image_key,
            "file_size": metadata["size"],
            "image_width": metadata.get("width"),
            "image_height": metadata.get("height")
        })
    
    # 4. Atualizar total de fotos
    await event_service.update_photo_count(event.id)
    
    # 5. Disparar processamento
    await trigger_processing(event.id)
    
    return event
```

#### 5.1.2. Pr√©-processamento

**Objetivo:** Otimizar imagens para API de vis√£o.

**Processo:**
1. Download da imagem do S3
2. Redimensionamento (1024x1024px, mant√©m aspect ratio)
3. Compress√£o JPEG (qualidade 85%)
4. Convers√£o para RGB
5. Upload para S3 processado (opcional, ou processar em mem√≥ria)

**C√≥digo:**
```python
async def preprocess_image(image_bytes: bytes) -> bytes:
    img = Image.open(io.BytesIO(image_bytes))
    img = img.convert('RGB')
    img.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
    
    output = io.BytesIO()
    img.save(output, format='JPEG', quality=85, optimize=True)
    return output.getvalue()
```

#### 5.1.3. Infer√™ncia de Vis√£o Computacional

**Objetivo:** Detectar marcas e produtos nas imagens.

**Processo:**
1. Agrupar imagens em batches de 10
2. Chamar API de vis√£o (Rekognition ou OpenAI)
3. Parse da resposta
4. Filtrar por confian√ßa m√≠nima (threshold: 0.6)
5. Salvar detec√ß√µes brutas no banco

**C√≥digo:**
```python
async def process_vision_batch(photos: List[Photo]) -> List[RawDetection]:
    detections = []
    
    for photo in photos:
        image_bytes = await s3_service.download(photo.s3_key)
        processed_image = await preprocess_image(image_bytes)
        
        # Chamada √† API
        response = await vision_service.detect(processed_image)
        
        # Parse e filtro
        for detection in response.detections:
            if detection.confidence >= 0.6:
                detections.append(RawDetection(
                    event_id=photo.event_id,
                    photo_id=photo.id,
                    detection_type=detection.type,
                    detected_label=detection.label,
                    confidence_score=detection.confidence,
                    raw_response=response.raw
                ))
    
    # Salvar em lote
    await db_writer.save_batch(detections)
    return detections
```

#### 5.1.4. Transforma√ß√£o e Enriquecimento

**Objetivo:** Normalizar dados e enriquecer com contexto.

**Processo:**
1. Normalizar nomes de marcas (via `brand_normalization`)
2. Classificar produtos (validar categoria)
3. Adicionar metadados do evento
4. Criar registros em `extracted_items`

**C√≥digo:**
```python
async def enrich_detections(raw_detections: List[RawDetection]) -> List[ExtractedItem]:
    enriched = []
    
    for detection in raw_detections:
        if detection.detection_type == 'brand':
            # Normalizar marca
            normalized = await brand_normalizer.normalize(detection.detected_label)
            
            enriched.append(ExtractedItem(
                event_id=detection.event_id,
                photo_id=detection.photo_id,
                item_type='brand',
                brand=detection.detected_label,
                normalized_brand=normalized,
                confidence_score=detection.confidence_score
            ))
        elif detection.detection_type == 'product':
            # Validar categoria
            product_type = await product_classifier.classify(detection.detected_label)
            
            enriched.append(ExtractedItem(
                event_id=detection.event_id,
                photo_id=detection.photo_id,
                item_type='product',
                product_type=product_type,
                confidence_score=detection.confidence_score
            ))
    
    await db_writer.save_extracted_items(enriched)
    return enriched
```

#### 5.1.5. Agrega√ß√£o

**Objetivo:** Calcular m√©tricas agregadas por evento.

**Processo:**
1. Agregar por marca (share, volume, confian√ßa m√©dia)
2. Agregar por produto (share, volume)
3. Calcular rankings
4. Atualizar views materializadas

**C√≥digo:**
```python
async def aggregate_event_metrics(event_id: UUID):
    # Agregar marcas
    brand_metrics = await aggregation_service.aggregate_brands(event_id)
    
    # Agregar produtos
    product_metrics = await aggregation_service.aggregate_products(event_id)
    
    # Atualizar views
    await db_service.refresh_materialized_views()
    
    # Atualizar status do evento
    await event_service.update_status(event_id, 'completed')
    
    return {
        "brand_metrics": brand_metrics,
        "product_metrics": product_metrics
    }
```

#### 5.1.6. Gera√ß√£o do Dataset Final

**Objetivo:** Criar tabelas anal√≠ticas prontas para consumo.

**Processo:**
1. Views materializadas j√° criadas (`brand_event_summary`, `product_event_summary`)
2. Exportar para CSV/Parquet (opcional)
3. Disponibilizar via API

#### 5.1.7. Gera√ß√£o do Relat√≥rio

**Objetivo:** Gerar relat√≥rio PDF com insights em linguagem natural.

**Processo:**
1. Buscar m√©tricas agregadas
2. Construir prompt para LLM
3. Chamar OpenAI API
4. Gerar PDF com template
5. Upload para S3
6. Registrar metadados

**C√≥digo:**
```python
async def generate_report(event_id: UUID) -> str:
    # 1. Buscar dados
    event = await event_service.get(event_id)
    brand_metrics = await aggregation_service.get_brand_metrics(event_id)
    product_metrics = await aggregation_service.get_product_metrics(event_id)
    
    # 2. Construir prompt
    prompt = prompt_builder.build_report_prompt(
        event=event,
        brands=brand_metrics,
        products=product_metrics
    )
    
    # 3. Chamar LLM
    llm_response = await llm_service.generate(prompt)
    
    # 4. Gerar PDF
    pdf_bytes = await pdf_generator.generate(
        event=event,
        narrative=llm_response.text,
        metrics=brand_metrics,
        charts=await chart_service.export_charts(event_id)
    )
    
    # 5. Upload S3
    s3_key = f"reports/{event_id}/report_{datetime.now().isoformat()}.pdf"
    await s3_service.upload(s3_key, pdf_bytes)
    
    # 6. Registrar
    await report_service.create({
        "event_id": event_id,
        "s3_key": s3_key,
        "report_type": "pdf"
    })
    
    return s3_key
```

### 5.2. Tecnologias Sugeridas

#### 5.2.1. Stack MVP Recomendada

**Decis√£o:** **AWS Serverless + PostgreSQL (RDS)**

| Componente | Tecnologia | Justificativa |
|------------|------------|---------------|
| **Processamento** | AWS Lambda | Custo-efetivo, escala autom√°tica, sem gerenciamento de servidor |
| **Orquestra√ß√£o** | EventBridge + Step Functions | Gerenciamento de fluxo complexo, retry autom√°tico |
| **Armazenamento Imagens** | S3 | Durabilidade, baixo custo, integra√ß√£o nativa |
| **Banco de Dados** | PostgreSQL (RDS) | Queries anal√≠ticas, relacionamentos, views materializadas |
| **API** | FastAPI (EC2/Fargate) | Async, f√°cil deploy, documenta√ß√£o autom√°tica |
| **Dashboard** | Metabase (EC2) | Open source, f√°cil conex√£o PostgreSQL |
| **LLM** | OpenAI API | Alta qualidade, f√°cil integra√ß√£o |

**Custo Estimado MVP:**
- Lambda: $0.20 por 1M requisi√ß√µes + $0.0000166667/GB-segundo
- RDS t3.medium: ~$70/m√™s
- S3: ~$0.023/GB armazenado
- OpenAI API: ~$0.03-0.06 por relat√≥rio
- **Total: ~$100-150/m√™s** (com uso moderado)

#### 5.2.2. Alternativa: Stack Local (Desenvolvimento)

Para desenvolvimento e testes locais:

```yaml
# docker-compose.yml
version: '3.8'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: midiaz_b2b
      POSTGRES_USER: midiaz
      POSTGRES_PASSWORD: midiaz123
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  minio:
    image: minio/minio
    command: server /data
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
  
  metabase:
    image: metabase/metabase
    ports:
      - "3000:3000"
    depends_on:
      - postgres
    environment:
      MB_DB_TYPE: postgres
      MB_DB_DBNAME: metabase
      MB_DB_PORT: 5432
      MB_DB_USER: midiaz
      MB_DB_PASS: midiaz123
      MB_DB_HOST: postgres

volumes:
  postgres_data:
```

**Uso:** Desenvolvimento local, testes, prototipagem r√°pida.

---

## 6. Plano de Evolu√ß√£o T√©cnica

### 6.1. v1 - Modelo Multi-Evento

**Objetivo:** Processar m√∫ltiplos eventos e comparar.

**Novas Features:**
- Compara√ß√£o entre eventos
- Tend√™ncias temporais
- Dashboard multi-evento
- API de compara√ß√£o

**Mudan√ßas T√©cnicas:**
- Adicionar tabela `event_comparisons`
- Views agregadas por per√≠odo
- Cache de m√©tricas (Redis)

### 6.2. v2 - Modelo Multi-Marca, Multi-Produto Detalhado

**Objetivo:** Detec√ß√£o mais granular e precisa.

**Novas Features:**
- Bounding boxes precisos
- Detec√ß√£o de modelos espec√≠ficos (ex: "Nike Air Max 270")
- Classifica√ß√£o de contexto (in√≠cio/fim de prova)
- Estimativa de idade/g√™nero (opcional)

**Mudan√ßas T√©cnicas:**
- Modelo customizado Rekognition treinado
- Fine-tuning cont√≠nuo
- Pipeline de anota√ß√£o de dados

### 6.3. v3 - API de Insights em Tempo Real

**Objetivo:** Processamento em tempo real durante eventos.

**Novas Features:**
- Processamento streaming (fotos chegam e s√£o processadas imediatamente)
- API WebSocket para atualiza√ß√µes em tempo real
- Dashboard com atualiza√ß√£o live
- Alertas de presen√ßa de marca

**Mudan√ßas T√©cnicas:**
- Kinesis Data Streams para ingest√£o
- Lambda com concurrency > 1
- WebSocket API (API Gateway)
- Cache Redis para m√©tricas em tempo real

### 6.4. v4 - √çndice Propriet√°rio de Marca

**Objetivo:** Criar √≠ndice nacional de presen√ßa de marca esportiva.

**Novas Features:**
- Agrega√ß√£o nacional de dados
- Ranking de marcas por regi√£o
- Tend√™ncias de mercado
- API p√∫blica de consulta

**Mudan√ßas T√©cnicas:**
- Data warehouse (Redshift ou BigQuery)
- ETL di√°rio/semanal
- API p√∫blica com rate limiting
- Autentica√ß√£o OAuth2

### 6.5. v5 - Infraestrutura Nacional de Intelig√™ncia Esportiva

**Objetivo:** Plataforma completa de intelig√™ncia esportiva.

**Novas Features:**
- M√∫ltiplos tipos de eventos (n√£o s√≥ corrida)
- An√°lise preditiva
- Recomenda√ß√µes de ativa√ß√£o
- Integra√ß√£o com CRMs

**Mudan√ßas T√©cnicas:**
- Arquitetura multi-tenant
- Machine Learning pr√≥prio (SageMaker)
- Microservi√ßos especializados
- Infraestrutura global (multi-region)

---

## 7. Roadmap de Desenvolvimento

### 7.1. Sprint 1 (2 semanas) - Ingest√£o + Dataset Bruto

**Objetivos:**
- Setup de infraestrutura b√°sica
- Ingest√£o de fotos do S3
- Registro de metadados do evento
- Valida√ß√£o de imagens

**Entregas:**
- [ ] Setup PostgreSQL (RDS ou local)
- [ ] Setup S3 bucket
- [ ] API FastAPI b√°sica (criar evento, listar eventos)
- [ ] M√≥dulo de ingest√£o (`ingestion/`)
- [ ] Tabelas do banco (`events`, `photos_raw`)
- [ ] Testes unit√°rios de ingest√£o

**Crit√©rio de Sucesso:**
- Consegue criar evento e registrar 100+ fotos
- Dados persistidos corretamente no banco

### 7.2. Sprint 2 (2 semanas) - Pipeline Completo + Extra√ß√£o

**Objetivos:**
- Integra√ß√£o com API de vis√£o
- Processamento batch de imagens
- Extra√ß√£o de marcas e produtos
- Persist√™ncia de detec√ß√µes

**Entregas:**
- [ ] M√≥dulo de pr√©-processamento (`preprocessing/`)
- [ ] Integra√ß√£o AWS Rekognition ou OpenAI Vision
- [ ] M√≥dulo de extra√ß√£o (`vision_extraction/`)
- [ ] Tabela `raw_detections`
- [ ] Processamento batch (Lambda ou script)
- [ ] Filtro por confian√ßa m√≠nima
- [ ] Testes de integra√ß√£o com API de vis√£o

**Crit√©rio de Sucesso:**
- Processa 1000+ imagens e extrai marcas/produtos
- Detec√ß√µes salvas no banco com confian√ßa > 0.6

### 7.3. Sprint 3 (2 semanas) - Dataset Anal√≠tico + M√©tricas

**Objetivos:**
- Normaliza√ß√£o de marcas
- Enriquecimento de dados
- Agrega√ß√£o de m√©tricas
- Views materializadas

**Entregas:**
- [ ] M√≥dulo de enriquecimento (`data_enrichment/`)
- [ ] Tabela `brand_normalization` (seed com marcas principais)
- [ ] Tabela `extracted_items`
- [ ] M√≥dulo de agrega√ß√£o (`aggregation/`)
- [ ] Views materializadas (`brand_event_summary`, `product_event_summary`)
- [ ] C√°lculo de shares e rankings
- [ ] Testes de agrega√ß√£o

**Crit√©rio de Sucesso:**
- M√©tricas calculadas corretamente
- Share de marca calculado e validado manualmente

### 7.4. Sprint 4 (2 semanas) - Relat√≥rio Anal√≠tico + Valida√ß√£o

**Objetivos:**
- Gera√ß√£o de relat√≥rio PDF com LLM
- Dashboard Metabase
- Valida√ß√£o com evento real
- Ajustes de qualidade

**Entregas:**
- [ ] M√≥dulo de gera√ß√£o de relat√≥rio (`report_generator/`)
- [ ] Integra√ß√£o OpenAI API
- [ ] Template de PDF
- [ ] Dashboard Metabase configurado
- [ ] Visualiza√ß√µes principais (4-6 gr√°ficos)
- [ ] Processamento de evento real (pilot)
- [ ] Valida√ß√£o de qualidade (precis√£o, recall)
- [ ] Ajustes baseados em feedback

**Crit√©rio de Sucesso:**
- Relat√≥rio PDF gerado com insights coerentes
- Dashboard funcional e explor√°vel
- Evento real processado com sucesso

### 7.5. Sprint 5 (1-2 semanas) - Ajustes + Entrega Final

**Objetivos:**
- Corre√ß√£o de bugs
- Otimiza√ß√µes de performance
- Documenta√ß√£o completa
- Deploy em produ√ß√£o

**Entregas:**
- [ ] Corre√ß√£o de bugs identificados
- [ ] Otimiza√ß√£o de queries (√≠ndices)
- [ ] Cache de resultados (se necess√°rio)
- [ ] Documenta√ß√£o t√©cnica completa
- [ ] README, CONTRIBUTING, BUILD.md
- [ ] Diagramas C4 atualizados
- [ ] Deploy em produ√ß√£o (AWS)
- [ ] Testes end-to-end
- [ ] Apresenta√ß√£o final

**Crit√©rio de Sucesso:**
- Sistema funcional em produ√ß√£o
- Documenta√ß√£o completa e clara
- Apresenta√ß√£o bem-sucedida

---

## 8. Riscos T√©cnicos e Mitiga√ß√µes

### 8.1. Erros do Modelo de Vis√£o

**Risco:** Modelo detecta marcas incorretas ou n√£o detecta marcas presentes.

**Mitiga√ß√£o:**
- **Threshold de confian√ßa:** Filtrar detec√ß√µes com confian√ßa < 0.6
- **Valida√ß√£o manual:** Amostra de 100 imagens validadas manualmente
- **Normaliza√ß√£o de marcas:** Mapear varia√ß√µes ("nike", "Nike", "NIKE") para "Nike"
- **Feedback loop:** Registrar falsos positivos/negativos para melhorar modelo

**Monitoramento:**
- Dashboard de qualidade (confian√ßa m√©dia, distribui√ß√£o)
- Alertas se confian√ßa m√©dia < 0.7

### 8.2. Varia√ß√£o de Ilumina√ß√£o

**Risco:** Imagens com baixa ilumina√ß√£o reduzem precis√£o.

**Mitiga√ß√£o:**
- **Pr√©-processamento:** Ajuste de brilho/contraste autom√°tico
- **Normaliza√ß√£o:** Histogram equalization
- **M√∫ltiplas tentativas:** Se confian√ßa baixa, tentar com imagem ajustada

**C√≥digo:**
```python
from PIL import ImageEnhance

def enhance_image(image: Image) -> Image:
    enhancer = ImageEnhance.Brightness(image)
    image = enhancer.enhance(1.2)  # Aumenta brilho 20%
    enhancer = ImageEnhance.Contrast(image)
    image = enhancer.enhance(1.1)  # Aumenta contraste 10%
    return image
```

### 8.3. Baixa Qualidade da Imagem

**Risco:** Imagens muito pequenas ou comprimidas reduzem detec√ß√£o.

**Mitiga√ß√£o:**
- **Valida√ß√£o na ingest√£o:** Rejeitar imagens < 100x100px
- **Upscaling:** Usar super-resolution (opcional, v2)
- **M√∫ltiplas escalas:** Tentar detec√ß√£o em diferentes tamanhos

**Valida√ß√£o:**
```python
def validate_image_quality(image_bytes: bytes) -> bool:
    img = Image.open(io.BytesIO(image_bytes))
    width, height = img.size
    
    if width < 100 or height < 100:
        return False
    
    if len(image_bytes) < 10 * 1024:  # < 10KB
        return False
    
    return True
```

### 8.4. Fotos sem Marca Aparente

**Risco:** Muitas fotos n√£o t√™m marca vis√≠vel (falsos negativos esperados).

**Mitiga√ß√£o:**
- **Expectativa realista:** N√£o esperar 100% de detec√ß√£o
- **M√©tricas de cobertura:** Reportar % de fotos com pelo menos 1 detec√ß√£o
- **Filtro de contexto:** Priorizar fotos de atletas (n√£o paisagem)

**M√©trica:**
```
Photo Coverage = (Fotos com detec√ß√£o / Total de fotos) √ó 100
Meta: > 40% de cobertura
```

### 8.5. Classifica√ß√£o Amb√≠gua

**Risco:** Produto pode ser classificado incorretamente (ex: "t√™nis" vs "sapato").

**Mitiga√ß√£o:**
- **Categorias bem definidas:** Lista fixa de categorias v√°lidas
- **Valida√ß√£o p√≥s-processamento:** Filtrar categorias inv√°lidas
- **Confian√ßa por categoria:** Threshold diferente por tipo de produto

**Categorias MVP:**
```python
VALID_PRODUCT_TYPES = [
    "t√™nis", "camiseta", "bon√©", "√≥culos", 
    "short", "meia", "rel√≥gio", "mochila"
]
```

### 8.6. Lat√™ncia de Processamento

**Risco:** Processar 10k+ imagens pode levar horas.

**Mitiga√ß√£o:**
- **Processamento paralelo:** M√∫ltiplas Lambdas em paralelo (com rate limiting)
- **Otimiza√ß√£o de batch:** Processar 10 imagens por requisi√ß√£o
- **Status ass√≠ncrono:** API retorna imediatamente, cliente consulta status
- **Notifica√ß√£o:** Webhook ou email quando processamento completo

**Estimativa:**
- 1 imagem = ~2-3 segundos (API + processamento)
- 10.000 imagens = ~5-8 horas (sequencial)
- Com paralelismo (10 workers): ~30-50 minutos

**C√≥digo de Paralelismo:**
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def process_event_parallel(event_id: UUID, max_workers: int = 10):
    photos = await photo_service.list_pending(event_id)
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        loop = asyncio.get_event_loop()
        tasks = [
            loop.run_in_executor(executor, process_photo, photo)
            for photo in photos
        ]
        await asyncio.gather(*tasks)
```

### 8.7. Custos de API

**Risco:** Custos de API de vis√£o podem explodir com volume alto.

**Mitiga√ß√£o:**
- **Cache de resultados:** N√£o reprocessar mesma imagem
- **Amostragem:** Processar amostra representativa (ex: 20% das fotos)
- **Otimiza√ß√£o de tamanho:** Reduzir tamanho da imagem antes do envio
- **Budget alerts:** Configurar alertas AWS/OpenAI para limites

**C√°lculo de Custo:**
- OpenAI Vision: $0.01-0.03/imagem
- 10.000 imagens = $100-300
- Com amostragem 20%: $20-60

**C√≥digo de Cache:**
```python
from functools import lru_cache
import hashlib

def get_image_hash(image_bytes: bytes) -> str:
    return hashlib.md5(image_bytes).hexdigest()

@lru_cache(maxsize=1000)
async def get_cached_detection(image_hash: str):
    # Verifica se j√° processou esta imagem
    cached = await cache.get(f"detection:{image_hash}")
    if cached:
        return cached
    return None
```

### 8.8. Escalabilidade do Banco

**Risco:** PostgreSQL pode ficar lento com milh√µes de detec√ß√µes.

**Mitiga√ß√£o:**
- **√çndices estrat√©gicos:** Criar √≠ndices em colunas de busca frequente
- **Particionamento:** Particionar tabelas por evento ou data (v2)
- **Views materializadas:** Pr√©-calcular agrega√ß√µes
- **Archiving:** Mover dados antigos para S3 (v2)

**√çndices Cr√≠ticos:**
```sql
CREATE INDEX idx_detections_event_type ON raw_detections(event_id, detection_type);
CREATE INDEX idx_detections_brand ON raw_detections(detected_label) WHERE detection_type = 'brand';
CREATE INDEX idx_items_event_brand ON extracted_items(event_id, normalized_brand);
```

---

## 9. Checklist Final

### 9.1. Funcionalidades Core

- [ ] Ingest√£o de fotos do S3 funcional
- [ ] Metadados do evento registrados corretamente
- [ ] Pr√©-processamento de imagens (resize, compress√£o)
- [ ] Integra√ß√£o com API de vis√£o (Rekognition ou OpenAI)
- [ ] Detec√ß√£o de marcas com confian√ßa > 0.6
- [ ] Detec√ß√£o de produtos categorizados
- [ ] Normaliza√ß√£o de marcas funcionando
- [ ] Agrega√ß√£o de m√©tricas (share, volume, ranking)
- [ ] Gera√ß√£o de relat√≥rio PDF com LLM
- [ ] Dashboard Metabase com visualiza√ß√µes principais

### 9.2. Qualidade de Dados

- [ ] Valida√ß√£o de imagens na ingest√£o
- [ ] Filtro de confian√ßa aplicado
- [ ] Normaliza√ß√£o de marcas testada
- [ ] M√©tricas calculadas corretamente (valida√ß√£o manual)
- [ ] Sem dados duplicados
- [ ] Integridade referencial (foreign keys)

### 9.3. Performance

- [ ] Processamento de 1000+ imagens em < 2 horas
- [ ] Queries de agrega√ß√£o < 5 segundos
- [ ] API responde em < 500ms (endpoints de consulta)
- [ ] Gera√ß√£o de relat√≥rio PDF < 30 segundos
- [ ] Dashboard carrega em < 3 segundos

### 9.4. Infraestrutura

- [ ] PostgreSQL configurado e acess√≠vel
- [ ] S3 buckets criados e configurados
- [ ] Lambda functions deployadas (se aplic√°vel)
- [ ] API FastAPI rodando e acess√≠vel
- [ ] Metabase configurado e conectado ao banco
- [ ] Vari√°veis de ambiente configuradas (secrets)
- [ ] Logs centralizados (CloudWatch ou similar)

### 9.5. Seguran√ßa

- [ ] Credenciais em vari√°veis de ambiente (n√£o hardcoded)
- [ ] S3 buckets com acesso restrito
- [ ] API com autentica√ß√£o b√°sica (se necess√°rio)
- [ ] Banco de dados com acesso restrito (security groups)
- [ ] Dados de atletas anonimizados (sem PII)

### 9.6. Documenta√ß√£o

- [ ] README.md completo e atualizado
- [ ] CONTRIBUTING.md com instru√ß√µes de setup
- [ ] BUILD.md com instru√ß√µes de build e deploy
- [ ] Diagramas C4 (Contexto, Cont√™iner, Componente)
- [ ] Documenta√ß√£o de API (Swagger/OpenAPI)
- [ ] Coment√°rios no c√≥digo (docstrings)
- [ ] Changelog ou hist√≥rico de mudan√ßas

### 9.7. Testes

- [ ] Testes unit√°rios para m√≥dulos principais (> 60% cobertura)
- [ ] Testes de integra√ß√£o com API de vis√£o (mocks)
- [ ] Testes end-to-end (processamento completo de evento)
- [ ] Valida√ß√£o manual com evento real
- [ ] Testes de carga (opcional, mas recomendado)

### 9.8. Valida√ß√£o com Stakeholders

- [ ] Evento real processado com sucesso
- [ ] Relat√≥rio PDF gerado e revisado
- [ ] Dashboard explorado por usu√°rio final
- [ ] Feedback coletado e incorporado
- [ ] M√©tricas de qualidade validadas (precis√£o, recall)

---

## 10. Conclus√£o e Pr√≥ximos Passos

### 10.1. Resumo do Plano

Este plano t√©cnico define a arquitetura, design e implementa√ß√£o do **Event Brand Report MVP**, produto anal√≠tico que transforma fotos esportivas em insights sobre presen√ßa de marca. O MVP foca em:

1. **Processamento de 1 evento completo** com detec√ß√£o de marcas e produtos
2. **Gera√ß√£o de m√©tricas agregadas** (share, volume, ranking)
3. **Entrega via dashboard e relat√≥rio PDF** com insights em linguagem natural

**Stack Principal:**
- **Backend:** FastAPI (Python)
- **Vis√£o:** AWS Rekognition ou OpenAI Vision API
- **Banco:** PostgreSQL (RDS)
- **Storage:** S3
- **Dashboard:** Metabase
- **LLM:** OpenAI GPT-4/3.5

**Custo Estimado:** ~$100-150/m√™s (com uso moderado)

**Timeline:** 5 sprints (10-12 semanas)

### 10.2. Pr√≥ximos Passos Imediatos

1. **Setup de Infraestrutura (Semana 1)**
   - Criar conta AWS (se n√£o tiver)
   - Setup RDS PostgreSQL
   - Criar S3 buckets
   - Configurar ambiente local (Docker Compose)

2. **Desenvolvimento Sprint 1 (Semanas 2-3)**
   - Implementar m√≥dulo de ingest√£o
   - Criar tabelas do banco
   - API b√°sica FastAPI
   - Testes unit√°rios

3. **Valida√ß√£o Cont√≠nua**
   - Processar evento piloto pequeno (100-200 imagens)
   - Validar qualidade das detec√ß√µes
   - Ajustar thresholds e normaliza√ß√µes

4. **Documenta√ß√£o Paralela**
   - Manter documenta√ß√£o atualizada
   - Registrar decis√µes t√©cnicas
   - Criar diagramas C4

### 10.3. Decis√µes Pendentes (Resolver nas Primeiras 2 Semanas)

1. **Escolha da API de Vis√£o:**
   - [ ] AWS Rekognition (customizado) ou OpenAI Vision (zero-shot)
   - **Recomenda√ß√£o:** Come√ßar com OpenAI (r√°pido), migrar para Rekognition customizado (v1)

2. **Estrat√©gia de Processamento:**
   - [ ] Lambda serverless ou EC2/Fargate
   - **Recomenda√ß√£o:** Lambda para MVP (custo-efetivo)

3. **Formato de Entrega Principal:**
   - [ ] Dashboard apenas, PDF apenas, ou ambos
   - **Recomenda√ß√£o:** Ambos (dashboard para explora√ß√£o, PDF para apresenta√ß√£o)

### 10.4. M√©tricas de Sucesso do MVP

**T√©cnicas:**
- ‚úÖ Processa 10.000+ imagens sem erros
- ‚úÖ Precis√£o de detec√ß√£o > 70% (valida√ß√£o manual)
- ‚úÖ Tempo de processamento < 8 horas para 10k imagens
- ‚úÖ Relat√≥rio PDF gerado com insights coerentes

**Neg√≥cio:**
- ‚úÖ Relat√≥rio √∫til para organizador de evento
- ‚úÖ Dashboard explor√°vel e intuitivo
- ‚úÖ M√©tricas validadas por stakeholder real
- ‚úÖ Case de sucesso documentado

### 10.5. Contatos e Recursos

**Equipe:**
- Matheus Augusto (L√≠der T√©cnico) - Coordena√ß√£o t√©cnica e arquitetura
- Lu√≠s Felipe Pascoal (Cientista de Dados) - IA e vis√£o computacional
- Rafaela Le√£o (Designer de Produto) - UX e valida√ß√£o com usu√°rios

**Recursos √öteis:**
- [AWS Rekognition Docs](https://docs.aws.amazon.com/rekognition/)
- [OpenAI Vision API](https://platform.openai.com/docs/guides/vision)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Metabase Documentation](https://www.metabase.com/docs/)

---

**Fim do Documento**

*Este plano t√©cnico √© um documento vivo e deve ser atualizado conforme o desenvolvimento avan√ßa e novas decis√µes s√£o tomadas.*

